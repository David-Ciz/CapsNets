{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XifengGuo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKbXyDg5Aq2J",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title outputs - plots/images\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:4]\n",
        "    image = np.zeros((height*shape[0], width*shape[1],shape[2]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, :]\n",
        "    print(num)\n",
        "    print(width)\n",
        "    print(height)\n",
        "    print(shape)\n",
        "    return image\n",
        "\n",
        "\n",
        "def combine_imagesOld(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 1]\n",
        "    print(num)\n",
        "    print(width)\n",
        "    print(height)\n",
        "    print(shape)\n",
        "    return image\n",
        "\n",
        "\n",
        "#if __name__==\"__main__\":\n",
        "#   plot_log('result/log.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FleNPhfZ3gX2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title layer construction\n",
        "\"\"\"\n",
        "Some key layers used for constructing a Capsule Network. These layers can used to construct CapsNet on other dataset, \n",
        "not just on MNIST.\n",
        "*NOTE*: some functions can be implemented in multiple ways, I keep all of them. You can try them for yourself just by\n",
        "uncommenting them and commenting their counterparts.\n",
        "Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "\"\"\"\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "def batch_dot(x, y, axes=None):\n",
        "    \"\"\"Batchwise dot product. Needed to use this one, as the new one in keras version 2.2.5 does not work correctly.\n",
        "\n",
        "    `batch_dot` is used to compute dot product of `x` and `y` when\n",
        "    `x` and `y` are data in batch, i.e. in a shape of\n",
        "    `(batch_size, :)`.\n",
        "    `batch_dot` results in a tensor or variable with less dimensions\n",
        "    than the input. If the number of dimensions is reduced to 1,\n",
        "    we use `expand_dims` to make sure that ndim is at least 2.\n",
        "\n",
        "    # Arguments\n",
        "        x: Keras tensor or variable with `ndim >= 2`.\n",
        "        y: Keras tensor or variable with `ndim >= 2`.\n",
        "        axes: list of (or single) int with target dimensions.\n",
        "            The lengths of `axes[0]` and `axes[1]` should be the same.\n",
        "\n",
        "    # Returns\n",
        "        A tensor with shape equal to the concatenation of `x`'s shape\n",
        "        (less the dimension that was summed over) and `y`'s shape\n",
        "        (less the batch dimension and the dimension that was summed over).\n",
        "        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n",
        "\n",
        "    # Examples\n",
        "        Assume `x = [[1, 2], [3, 4]]` and `y = [[5, 6], [7, 8]]`\n",
        "        `batch_dot(x, y, axes=1) = [[17], [53]]` which is the main diagonal\n",
        "        of `x.dot(y.T)`, although we never have to calculate the off-diagonal\n",
        "        elements.\n",
        "\n",
        "        Shape inference:\n",
        "        Let `x`'s shape be `(100, 20)` and `y`'s shape be `(100, 30, 20)`.\n",
        "        If `axes` is (1, 2), to find the output shape of resultant tensor,\n",
        "            loop through each dimension in `x`'s shape and `y`'s shape:\n",
        "\n",
        "        * `x.shape[0]` : 100 : append to output shape\n",
        "        * `x.shape[1]` : 20 : do not append to output shape,\n",
        "            dimension 1 of `x` has been summed over. (`dot_axes[0]` = 1)\n",
        "        * `y.shape[0]` : 100 : do not append to output shape,\n",
        "            always ignore first dimension of `y`\n",
        "        * `y.shape[1]` : 30 : append to output shape\n",
        "        * `y.shape[2]` : 20 : do not append to output shape,\n",
        "            dimension 2 of `y` has been summed over. (`dot_axes[1]` = 2)\n",
        "        `output_shape` = `(100, 30)`\n",
        "\n",
        "    ```python\n",
        "        >>> x_batch = K.ones(shape=(32, 20, 1))\n",
        "        >>> y_batch = K.ones(shape=(32, 30, 20))\n",
        "        >>> xy_batch_dot = K.batch_dot(x_batch, y_batch, axes=[1, 2])\n",
        "        >>> K.int_shape(xy_batch_dot)\n",
        "        (32, 1, 30)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    if isinstance(axes, int):\n",
        "        axes = (axes, axes)\n",
        "    x_ndim = K.ndim(x)\n",
        "    y_ndim = K.ndim(y)\n",
        "    if axes is None:\n",
        "        # behaves like tf.batch_matmul as default\n",
        "        axes = [x_ndim - 1, y_ndim - 2]\n",
        "    if x_ndim > y_ndim:\n",
        "        diff = x_ndim - y_ndim\n",
        "        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n",
        "    elif y_ndim > x_ndim:\n",
        "        diff = y_ndim - x_ndim\n",
        "        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n",
        "    else:\n",
        "        diff = 0\n",
        "    if K.ndim(x) == 2 and K.ndim(y) == 2:\n",
        "        if axes[0] == axes[1]:\n",
        "            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n",
        "        else:\n",
        "            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n",
        "    else:\n",
        "        if axes is not None:\n",
        "            adj_x = None if axes[0] == K.ndim(x) - 1 else True\n",
        "            adj_y = True if axes[1] == K.ndim(y) - 1 else None\n",
        "        else:\n",
        "            adj_x = None\n",
        "            adj_y = None\n",
        "        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n",
        "    if diff:\n",
        "        if x_ndim > y_ndim:\n",
        "            idx = x_ndim + y_ndim - 3\n",
        "        else:\n",
        "            idx = x_ndim - 1\n",
        "        out = tf.squeeze(out, list(range(idx, idx + diff)))\n",
        "    if K.ndim(out) == 1:\n",
        "        out = expand_dims(out, 1)\n",
        "    return out\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    \n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
        "        inputs_expand = K.expand_dims(inputs, 1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # Regard the first two dimensions as `batch` dimension,\n",
        "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = K.map_fn(lambda x: batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, dim=1)\n",
        "\n",
        "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
        "            outputs = squash(batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension,\n",
        "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "                b += batch_dot(outputs, inputs_hat, [2, 3])\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n",
        "\n",
        "# The following is another way to implement primary capsule layer. This is much slower.\n",
        "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "# def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "#    outputs = []\n",
        "#    for _ in range(n_channels):\n",
        "#        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "#        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
        "#    outputs = layers.Concatenate(axis=1)(outputs)\n",
        "#    return layers.Lambda(squash)(outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss1Lb0jNAl6X",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title architecture setup and def train { form-width: \"10%\" }\n",
        "\"\"\"\n",
        "Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
        "Adopting to other backends should be easy, but I have not tested this. \n",
        "Usage:\n",
        "       python capsulenet.py\n",
        "       python capsulenet.py --epochs 50\n",
        "       python capsulenet.py --epochs 50 --routings 3\n",
        "       ... ...\n",
        "       \n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Converge to 99.66% after 50 epochs.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n",
        "Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "    \n",
        "    \n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
        "                             name='digitcaps')(primarycaps)\n",
        "    \n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "    \n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "    \n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model\n",
        "\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n",
        "\n",
        "\n",
        "def train(model, data, args, model_num):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n",
        "                               batch_size=args.batch_size, histogram_freq=int(args.debug))\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    \"\"\"\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
        "    def train_generatorForTTA(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=False,\n",
        "        rotation_range=10.,\n",
        "        fill_mode='reflect',\n",
        "        width_shift_range = 0.1, \n",
        "        height_shift_range = 0.1\n",
        "        )\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
        "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
        "    model.fit_generator(generator=train_generatorForTTA(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "                        steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "                        epochs=args.epochs,\n",
        "                        validation_data=[[x_test, y_test], [y_test, x_test]],\n",
        "                        callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model' + str(model_num) +'.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model%s.h5\\'' % args.save_dir %args.model_num)\n",
        "\n",
        "\n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print(np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)))\n",
        "    print('-'*30 + 'Begin: test' + '-'*30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "    print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    plt.imshow(x_recon[5])\n",
        "    plt.show()\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8),'RGB').save(args.save_dir + \"/real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    plt.show()\n",
        "\n",
        "def testForEnsemble(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print(np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)))\n",
        "    print(y_test.shape[0])\n",
        "    print('-'*30 + 'Begin: test' + '-'*30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "    return y_pred\n",
        "\n",
        "def testWithTTA(model, data, args):\n",
        "  x_test, y_test = data\n",
        "  test_Datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=False,\n",
        "        width_shift_range = 0.1, \n",
        "        height_shift_range = 0.1\n",
        "        )\n",
        "  tta_steps = 10\n",
        "  predictions = []\n",
        "\n",
        "  for i in range(0, 1):\n",
        "      preds, _ = model.predict_generator(test_Datagen.flow(x_test, batch_size=100, shuffle=False), steps = len(x_test)/100)\n",
        "      preds = np.asarray(preds)\n",
        "      print(f'1. augmentation accuracy:  {np.mean(np.equal(np.argmax(y_test,axis=1),np.argmax(preds,axis=1)))}') \n",
        "\n",
        "\n",
        "  for i in range(1, tta_steps):\n",
        "      predsx, _ = model.predict_generator(test_Datagen.flow(x_test, batch_size=100, shuffle=False), steps = len(x_test)/100)\n",
        "      predsx = np.asarray(predsx)\n",
        "      predsy = preds+predsx\n",
        "      print(f'%d. augmentation accuracy:  {np.mean(np.equal(np.argmax(y_test,axis=1),np.argmax(predsx,axis=1)))}'%(i+1))\n",
        "  final_pred = np.argmax(predsy, axis=1)\n",
        "  print(final_pred.shape)\n",
        "  print(f'Accuracy with TTA: {np.mean(np.equal(np.argmax(y_test, axis=1), final_pred))}')\n",
        "\n",
        "\n",
        "def manipulate_latent(model, data, args):\n",
        "    print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
        "    x_test, y_test = data\n",
        "    index = np.argmax(y_test, 1) == args.digit\n",
        "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
        "    x, y = x_test[index][number], y_test[index][number]\n",
        "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
        "    noise = np.zeros([1, 10, 16])\n",
        "    x_recons = []\n",
        "    for dim in range(16):\n",
        "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "            tmp = np.copy(noise)\n",
        "            tmp[:,:,dim] = r\n",
        "            x_recon = model.predict([x, y, tmp])\n",
        "            x_recons.append(x_recon)\n",
        "\n",
        "    x_recons = np.concatenate(x_recons)\n",
        "\n",
        "    img = combine_images(x_recons, height=16)\n",
        "    image = img*255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
        "    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
        "    print('-' * 30 + 'End: manipulate' + '-' * 30)\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    from keras.datasets import mnist\n",
        "    random_seed = 2\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size = 0.16666, random_state=random_seed)\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_train, y_train),(x_val,y_val), (x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDfQoymp9hIe",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ModifiedMnistLoader\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "def load_modified_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_trainModified=np.zeros((60000,28,28,3),dtype=int)\n",
        "    for x in range(x_train.shape[0]):\n",
        "      x_trainModified[x] = cv2.cvtColor(x_train[x],cv2.COLOR_GRAY2RGB)\n",
        "    x_testModified=np.zeros((10000,28,28,3),dtype=int)\n",
        "    for x in range(x_test.shape[0]):\n",
        "      x_testModified[x] = cv2.cvtColor(x_test[x],cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    !wget \"https://images2.alphacoders.com/101/1011957.jpg\"\n",
        "    sourceImage = mpimg.imread('1011957.jpg')\n",
        "\n",
        "    sourceWidth = sourceImage.shape[1]\n",
        "    sourceHeight = sourceImage.shape[0]\n",
        "    width = 28\n",
        "    height = 28\n",
        "\n",
        "    for x in range(60000):\n",
        "     x1 = random.randint(0, sourceWidth-width-1)\n",
        "     y1 = random.randint(0, sourceHeight-height-1)\n",
        "     croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "     for row in range(x_trainModified[x].shape[0]):\n",
        "        for pixel in range(x_trainModified[x].shape[1]):\n",
        "         if all(i<140 for i in x_trainModified[x][row][pixel]):\n",
        "           x_trainModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "\n",
        "    for x in range(10000):\n",
        "      x1 = random.randint(0, sourceWidth-width-1)\n",
        "      y1 = random.randint(0, sourceHeight-height-1)\n",
        "      croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "      for row in range(x_testModified[x].shape[0]):\n",
        "        for pixel in range(x_testModified[x].shape[1]):\n",
        "          if all(i<140 for i in x_testModified[x][row][pixel]):\n",
        "            x_testModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "    \n",
        "    x_trainModified = x_trainModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "    x_testModified = x_testModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_trainModified, y_train), (x_testModified, y_test)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMD1S6Yf4gYY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cifar10Loader\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "def load_cifar10():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  x_train = x_train.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
        "  x_test = x_test.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
        "  y_train = to_categorical(y_train.astype('float32'))\n",
        "  y_test = to_categorical(y_test.astype('float32'))\n",
        "  return (x_train, y_train), (x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "-n20w40t-a_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ba98d83f-4e5f-42aa-cce2-7b2fa3115e3d"
      },
      "source": [
        "#@title Run { form-width: \"10%\" }\n",
        "!pip install easydict\n",
        "import os\n",
        "import argparse\n",
        "import easydict\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "\n",
        "\n",
        "# setting the hyper parameters\n",
        "#parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
        "#parser.add_argument('--epochs', default=50, type=int)\n",
        "#parser.add_argument('--batch_size', default=100, type=int)\n",
        "#parser.add_argument('--lr', default=0.001, type=float,\n",
        "#                    help=\"Initial learning rate\")\n",
        "#parser.add_argument('--lr_decay', default=0.9, type=float,\n",
        "#                    help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
        "#parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "#                    help=\"The coefficient for the loss of decoder\")\n",
        "#parser.add_argument('-r', '--routings', default=3, type=int,\n",
        "#                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "#parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
        "#                    help=\"Fraction of pixels to shift at most in each direction.\")\n",
        "#parser.add_argument('--debug', action='store_true',\n",
        "#                    help=\"Save weights by TensorBoard\")\n",
        "#parser.add_argument('--save_dir', default='./result')\n",
        "#parser.add_argument('-t', '--testing', action='store_true',\n",
        "#                    help=\"Test the trained model on testing dataset\")\n",
        "#parser.add_argument('--digit', default=5, type=int,\n",
        "#                    help=\"Digit to manipulate\")\n",
        "#parser.add_argument('-w', '--weights', default=None,\n",
        "#                    help=\"The path of the saved weights. Should be specified when testing\")\n",
        "args = easydict.EasyDict({\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 100,\n",
        "    'train_steps': 1000, \n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.392,\n",
        "    \"routings\": 3,\n",
        "    \"shift_fraction\": 0.1,\n",
        "    \"save_dir\": 'result',\n",
        "    \"digit\": 5,\n",
        "    \"debug\": False,\n",
        "    \"testing\": False,\n",
        "    \"weights\": \"trained_model1.h5\",\n",
        "    \"ensemble\": 1,\n",
        "    \"dataset\": 'mnist' \n",
        "})\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)\n",
        "\n",
        "# load data\n",
        "if (args.dataset==\"mnist\"):\n",
        "  (x_train, y_train),(x_val, y_val), (x_test, y_test) = load_mnist()\n",
        "elif(args.dataset==\"mnistModified\"):\n",
        "  (x_train, y_train), (x_test, y_test) = load_modified_mnist()\n",
        "elif(args.dataset==\"cifar10\"):\n",
        "  (x_train,y_train), (x_test, y_test) = load_cifar10()\n",
        "\n",
        "# define models\n",
        "\n",
        "model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                                routings=args.routings)\n",
        "\n",
        "for i in range(args.ensemble):\n",
        "  if(args.testing==False):\n",
        "    train(model=model, data=((x_train, y_train), (x_val, y_val)), args=args, model_num=i)\n",
        "  else:\n",
        "    model.load_weights(args.weights)\n",
        "    testWithTTA(model=eval_model, data=(x_test, y_test), args=args)\n",
        "    test(model=eval_model, data=(x_test, y_test), args=args)\n",
        "\n",
        "#partialXStartingPoint=0\n",
        "#if args.testing==False:\n",
        "#  for i in range(args.ensemble):\n",
        "#    train_size = int(x_train.shape[0]/args.ensemble)\n",
        "#    x_trainPartial = x_train[partialXStartingPoint:partialXStartingPoint+train_size]\n",
        "#    y_trainPartial = y_train[partialXStartingPoint:partialXStartingPoint+train_size]\n",
        "#    partialXStartingPoint+=train_size\n",
        "#     model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "#                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "#                                                routings=args.routings)\n",
        "#else:\n",
        "\n",
        "\n",
        "#model.load_weights(args.weights)\n",
        "#testWithTTA(model=eval_model, data=(x_test,y_test),args=args)\n",
        "#  y_summed = []\n",
        "#  for i in range(args.ensemble):\n",
        "#    model.load_weights(str('trained_model' + str(i) + '.h5'))\n",
        "#    model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "#                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "#                                                routings=args.routings)\n",
        "#    y_pred = testForEnsemble(model=eval_model, data=(x_test, y_test), args=args)\n",
        "#    if(i==0):\n",
        "#      y_summed= np.array(y_pred)\n",
        "#    else:\n",
        "#      y_summed += np.array(y_pred)\n",
        "#  print(np.sum(np.argmax(y_summed, 1) == np.argmax(y_test, 1)))\n",
        "#  print(y_test.shape[0])\n",
        "#  print('-'*30 + 'Ensemble results: ' + '-'*30)\n",
        "#  print('Test acc:', np.sum(np.argmax(y_summed, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "#  train(model=model, data=((x_trainPartial, y_trainPartial), (x_test, y_test)), args=args, model_num=i)\n",
        "# train or test\n",
        "#if args.weights is not None:  # init the model weights with provided one\n",
        "#    model.load_weights(args.weights)\n",
        "#if not args.testing:\n",
        "#    \n",
        "#else:  # as long as weights are given, will run testing\n",
        "#    if args.weights is None:\n",
        "#        print('No weights are provided. Will test using random initialized weights.')\n",
        "#    #manipulate_latent(manipulate_model, (x_test, y_test), args)\n",
        "#    test(model=eval_model, data=(x_test, y_test), args=args)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Epoch 1/50\n",
            "  1/500 [..............................] - ETA: 14:19 - loss: 0.8961 - capsnet_loss: 0.8100 - decoder_loss: 0.2195 - capsnet_acc: 0.0800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3a85716d5114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ed6f14133403>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, args, model_num)\u001b[0m\n\u001b[1;32m    147\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                         callbacks=[log, tb, checkpoint, lr_decay])\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;31m# End: Training with data augmentation -----------------------------------------------------------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqcAANO99OGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"file\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibCEQ19Ppko",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title check gpu\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}