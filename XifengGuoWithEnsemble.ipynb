{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsKerasWithEnsemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4DpobhLsvZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKbXyDg5Aq2J",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title outputs - plots/images\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:4]\n",
        "    image = np.zeros((height*shape[0], width*shape[1],shape[2]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, :]\n",
        "    print(num)\n",
        "    print(width)\n",
        "    print(height)\n",
        "    print(shape)\n",
        "    return image\n",
        "\n",
        "\n",
        "def combine_imagesOld(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 1]\n",
        "    print(num)\n",
        "    print(width)\n",
        "    print(height)\n",
        "    print(shape)\n",
        "    return image\n",
        "\n",
        "\n",
        "#if __name__==\"__main__\":\n",
        "#   plot_log('result/log.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FleNPhfZ3gX2",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title layer construction\n",
        "\"\"\"\n",
        "Some key layers used for constructing a Capsule Network. These layers can used to construct CapsNet on other dataset, \n",
        "not just on MNIST.\n",
        "*NOTE*: some functions can be implemented in multiple ways, I keep all of them. You can try them for yourself just by\n",
        "uncommenting them and commenting their counterparts.\n",
        "Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "\"\"\"\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    \n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    print(\"fine\")\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "    \n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
        "        inputs_expand = K.expand_dims(inputs, 1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # Regard the first two dimensions as `batch` dimension,\n",
        "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, dim=1)\n",
        "\n",
        "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
        "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension,\n",
        "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
        "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# The following is another way to implement primary capsule layer. This is much slower.\n",
        "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    outputs = []\n",
        "    for _ in range(n_channels):\n",
        "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
        "    outputs = layers.Concatenate(axis=1)(outputs)\n",
        "    return layers.Lambda(squash)(outputs)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss1Lb0jNAl6X",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title architecture setup and def train { form-width: \"10%\" }\n",
        "\"\"\"\n",
        "Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
        "Adopting to other backends should be easy, but I have not tested this. \n",
        "Usage:\n",
        "       python capsulenet.py\n",
        "       python capsulenet.py --epochs 50\n",
        "       python capsulenet.py --epochs 50 --routings 3\n",
        "       ... ...\n",
        "       \n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Converge to 99.66% after 50 epochs.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n",
        "Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "    \n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "    print(primarycaps.shape)\n",
        "    \n",
        "    \n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
        "                             name='digitcaps')(primarycaps)\n",
        "    \n",
        "    print(\"notfine\")\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "    \n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "    \n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model\n",
        "\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n",
        "\n",
        "\n",
        "def train(model, data, args, model_num):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n",
        "                               batch_size=args.batch_size, histogram_freq=int(args.debug))\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    \"\"\"\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
        "    model.fit_generator(generator=train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "                        steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "                        epochs=args.epochs*args.ensemble,\n",
        "                        validation_data=[[x_test, y_test], [y_test, x_test]],\n",
        "                        callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model' + str(model_num) +'.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
        "\n",
        "\n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print(np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)))\n",
        "    print(y_test.shape[0])\n",
        "    print('-'*30 + 'Begin: test' + '-'*30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "    print(y_test.shape[0])\n",
        "    print(y_pred[1])\n",
        "    print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    plt.imshow(x_recon[5])\n",
        "    plt.show()\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8),'RGB').save(args.save_dir + \"/real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    plt.show()\n",
        "\n",
        "def testForEnsemble(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
        "    print(np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)))\n",
        "    print(y_test.shape[0])\n",
        "    print('-'*30 + 'Begin: test' + '-'*30)\n",
        "    print(f'%d. Test accuracy run:  {np.mean(np.equal(np.argmax(y_test,axis=1),np.argmax(y_pred,axis=1)))}'%(i+1))\n",
        "    #print(y_test.shape[0])\n",
        "    #print(y_pred[1])\n",
        "    #print(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
        "    #img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
        "    #plt.imshow(img)\n",
        "    #plt.show()\n",
        "    #plt.imshow(x_recon[5])\n",
        "    #plt.show()\n",
        "    #image = img * 255\n",
        "    #Image.fromarray(image.astype(np.uint8),'RGB').save(args.save_dir + \"/real_and_recon.png\")\n",
        "    #print()\n",
        "    #print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    #print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    #plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    #plt.show()\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def manipulate_latent(model, data, args):\n",
        "    print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
        "    x_test, y_test = data\n",
        "    index = np.argmax(y_test, 1) == args.digit\n",
        "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
        "    x, y = x_test[index][number], y_test[index][number]\n",
        "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
        "    noise = np.zeros([1, 10, 16])\n",
        "    x_recons = []\n",
        "    for dim in range(16):\n",
        "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
        "            tmp = np.copy(noise)\n",
        "            tmp[:,:,dim] = r\n",
        "            x_recon = model.predict([x, y, tmp])\n",
        "            x_recons.append(x_recon)\n",
        "\n",
        "    x_recons = np.concatenate(x_recons)\n",
        "\n",
        "    img = combine_images(x_recons, height=16)\n",
        "    image = img*255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
        "    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
        "    print('-' * 30 + 'End: manipulate' + '-' * 30)\n",
        "\n",
        "\n",
        "def load_mnist():\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    from keras.datasets import mnist\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_train, y_train), (x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDfQoymp9hIe",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ModifiedMnistLoader\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "def load_modified_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_trainModified=np.zeros((60000,28,28,3),dtype=int)\n",
        "    for x in range(x_train.shape[0]):\n",
        "      x_trainModified[x] = cv2.cvtColor(x_train[x],cv2.COLOR_GRAY2RGB)\n",
        "    x_testModified=np.zeros((10000,28,28,3),dtype=int)\n",
        "    for x in range(x_test.shape[0]):\n",
        "      x_testModified[x] = cv2.cvtColor(x_test[x],cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    !wget \"https://images2.alphacoders.com/101/1011957.jpg\"\n",
        "    sourceImage = mpimg.imread('1011957.jpg')\n",
        "\n",
        "    sourceWidth = sourceImage.shape[1]\n",
        "    sourceHeight = sourceImage.shape[0]\n",
        "    width = 28\n",
        "    height = 28\n",
        "\n",
        "    for x in range(60000):\n",
        "     x1 = random.randint(0, sourceWidth-width-1)\n",
        "     y1 = random.randint(0, sourceHeight-height-1)\n",
        "     croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "     for row in range(x_trainModified[x].shape[0]):\n",
        "        for pixel in range(x_trainModified[x].shape[1]):\n",
        "         if all(i<140 for i in x_trainModified[x][row][pixel]):\n",
        "           x_trainModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "\n",
        "    for x in range(10000):\n",
        "      x1 = random.randint(0, sourceWidth-width-1)\n",
        "      y1 = random.randint(0, sourceHeight-height-1)\n",
        "      croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "      for row in range(x_testModified[x].shape[0]):\n",
        "        for pixel in range(x_testModified[x].shape[1]):\n",
        "          if all(i<140 for i in x_testModified[x][row][pixel]):\n",
        "            x_testModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "    \n",
        "    x_trainModified = x_trainModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "    x_testModified = x_testModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_trainModified, y_train), (x_testModified, y_test)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMD1S6Yf4gYY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cifar10Loader\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "def load_cifar10():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  x_train = x_train.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
        "  x_test = x_test.reshape(-1, 32, 32, 3).astype('float32') / 255.\n",
        "  y_train = to_categorical(y_train.astype('float32'))\n",
        "  y_test = to_categorical(y_test.astype('float32'))\n",
        "  return (x_train, y_train), (x_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIquICsfiNEz",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "9c04c67a-77a8-45ca-a1c1-6e28cce7af3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "#@title Run\n",
        "!pip install easydict\n",
        "import os\n",
        "import argparse\n",
        "import easydict\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "\n",
        "\n",
        "# setting the hyper parameters\n",
        "#parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
        "#parser.add_argument('--epochs', default=50, type=int)\n",
        "#parser.add_argument('--batch_size', default=100, type=int)\n",
        "#parser.add_argument('--lr', default=0.001, type=float,\n",
        "#                    help=\"Initial learning rate\")\n",
        "#parser.add_argument('--lr_decay', default=0.9, type=float,\n",
        "#                    help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
        "#parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "#                    help=\"The coefficient for the loss of decoder\")\n",
        "#parser.add_argument('-r', '--routings', default=3, type=int,\n",
        "#                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "#parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
        "#                    help=\"Fraction of pixels to shift at most in each direction.\")\n",
        "#parser.add_argument('--debug', action='store_true',\n",
        "#                    help=\"Save weights by TensorBoard\")\n",
        "#parser.add_argument('--save_dir', default='./result')\n",
        "#parser.add_argument('-t', '--testing', action='store_true',\n",
        "#                    help=\"Test the trained model on testing dataset\")\n",
        "#parser.add_argument('--digit', default=5, type=int,\n",
        "#                    help=\"Digit to manipulate\")\n",
        "#parser.add_argument('-w', '--weights', default=None,\n",
        "#                    help=\"The path of the saved weights. Should be specified when testing\")\n",
        "args = easydict.EasyDict({\n",
        "    \"epochs\": 50,\n",
        "    \"batch_size\": 100,\n",
        "    'train_steps': 1000, \n",
        "    \"lr\": 0.001,\n",
        "    \"lr_decay\": 0.9,\n",
        "    \"lam_recon\": 0.392,\n",
        "    \"routings\": 3,\n",
        "    \"shift_fraction\": 0.1,\n",
        "    \"save_dir\": 'result',\n",
        "    \"digit\": 5,\n",
        "    \"debug\": False,\n",
        "    \"testing\": True,\n",
        "    \"weights\": \"trained_model.h5\",\n",
        "    \"ensemble\": 5    \n",
        "})\n",
        "\n",
        "#args = parser.parse_args()\n",
        "print(args)\n",
        "\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)\n",
        "\n",
        "# load data\n",
        "(x_train, y_train), (x_test, y_test) = load_mnist()\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = load_modified_mnist()\n",
        "\n",
        "#(x_train,y_train), (x_test, y_test) = load_cifar10()\n",
        "# define models\n",
        "partialXStartingPoint=0\n",
        "if args.testing==False:\n",
        "  for i in range(args.ensemble):\n",
        "    train_size = int(x_train.shape[0]/args.ensemble)\n",
        "    x_trainPartial = x_train[partialXStartingPoint:partialXStartingPoint+train_size]\n",
        "    y_trainPartial = y_train[partialXStartingPoint:partialXStartingPoint+train_size]\n",
        "    partialXStartingPoint+=train_size\n",
        "    model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                                routings=args.routings)\n",
        "    train(model=model, data=((x_trainPartial, y_trainPartial), (x_test, y_test)), args=args, model_num=i)\n",
        "    \n",
        "else:\n",
        "  y_summed = []\n",
        "  for i in range(args.ensemble):\n",
        "\n",
        "    model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                                routings=args.routings)\n",
        "    model.load_weights(str('trained_model' + str(i) + '.h5'))\n",
        "    y_pred = testForEnsemble(model=eval_model, data=(x_test, y_test), args=args)\n",
        "    if(i==0):\n",
        "      y_summed= np.array(y_pred)\n",
        "    else:\n",
        "      y_summed += np.array(y_pred)\n",
        "  print(np.sum(np.argmax(y_summed, 1) == np.argmax(y_test, 1)))\n",
        "  print(y_test.shape[0])\n",
        "  print('-'*30 + 'Ensemble results: ' + '-'*30)\n",
        "  print(f'%d. Ensemble accuracy:  {np.mean(np.equal(np.argmax(y_test,axis=1),np.argmax(y_pred,axis=1)))}'%(i+1))\n",
        "  print('Test acc:', np.sum(np.argmax(y_summed, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "#  \n",
        "# train or test\n",
        "#if args.weights is not None:  # init the model weights with provided one\n",
        "#    model.load_weights(args.weights)\n",
        "#if not args.testing:\n",
        "#    \n",
        "#else:  # as long as weights are given, will run testing\n",
        "#    if args.weights is None:\n",
        "#        print('No weights are provided. Will test using random initialized weights.')\n",
        "#    #manipulate_latent(manipulate_model, (x_test, y_test), args)\n",
        "#    test(model=eval_model, data=(x_test, y_test), args=args)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: easydict in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "{'epochs': 50, 'batch_size': 100, 'train_steps': 1000, 'lr': 0.001, 'lr_decay': 0.9, 'lam_recon': 0.392, 'routings': 3, 'shift_fraction': 0.1, 'save_dir': 'result', 'digit': 5, 'debug': False, 'testing': True, 'weights': 'trained_model.h5', 'ensemble': 5}\n",
            "(?, ?, 8)\n",
            "notfine\n",
            "9964\n",
            "10000\n",
            "------------------------------Begin: test------------------------------\n",
            "1. Test accuracy run:  0.9964\n",
            "(?, ?, 8)\n",
            "notfine\n",
            "9963\n",
            "10000\n",
            "------------------------------Begin: test------------------------------\n",
            "2. Test accuracy run:  0.9963\n",
            "(?, ?, 8)\n",
            "notfine\n",
            "9957\n",
            "10000\n",
            "------------------------------Begin: test------------------------------\n",
            "3. Test accuracy run:  0.9957\n",
            "(?, ?, 8)\n",
            "notfine\n",
            "9964\n",
            "10000\n",
            "------------------------------Begin: test------------------------------\n",
            "4. Test accuracy run:  0.9964\n",
            "(?, ?, 8)\n",
            "notfine\n",
            "9960\n",
            "10000\n",
            "------------------------------Begin: test------------------------------\n",
            "5. Test accuracy run:  0.996\n",
            "9964\n",
            "10000\n",
            "------------------------------Ensemble results: ------------------------------\n",
            "5. Ensemble accuracy:  0.996\n",
            "Test acc: 0.9964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XibCEQ19Ppko",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title check gpu\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}