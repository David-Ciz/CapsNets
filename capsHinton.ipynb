{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsHinton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s6gCrWPhKey",
        "colab_type": "text"
      },
      "source": [
        "# Run all cells in order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Em0TcvLFX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/naturomics/capsule-model-forked-from-Sarasra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfM0BML6kLE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd capsule-model-forked-from-Sarasra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP25cbsoCEkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://storage.googleapis.com/capsule_toronto/mnist_data.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4J5CkY2N_DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPAyIbIuC8UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://storage.googleapis.com/capsule_toronto/mnist_checkpoints.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFwzIxizCX7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvzf mnist_data.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-MwRjrt-63a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jki3b5-OYdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvzf cifar-10-binary.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvhpf-9BDGb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xvzf mnist_checkpoints.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shB0E5EaMiks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uploading weights if necessary\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyGpz5QR_1sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -czf hintonResultsCifar.tar.gz model.ckpt-24000.data-00000-of-00001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O5MkXBDhonP",
        "colab_type": "text"
      },
      "source": [
        "Edit this with your hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T91R_EreXegq",
        "colab_type": "code",
        "outputId": "c76256b3-7dd0-4241-b245-9809f8afbf90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile experiment.py\n",
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Framework for training and evaluating models.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from input_data.cifar10 import cifar10_input\n",
        "from input_data.mnist import mnist_input_record\n",
        "from input_data.norb import norb_input_record\n",
        "from models import capsule_model\n",
        "from models import conv_model\n",
        "\n",
        "FLAGS = tf.flags.FLAGS\n",
        "\n",
        "tf.flags.DEFINE_string('data_dir', 'mnist_data', 'The data directory.')\n",
        "tf.flags.DEFINE_integer('eval_size', 10000, 'Size of the test dataset.')\n",
        "tf.flags.DEFINE_string('hparams_override', None,\n",
        "                       'A string of form key=value,key=value to override the'\n",
        "                       'hparams of this experiment.')\n",
        "tf.flags.DEFINE_integer('max_steps', 24000, 'Number of steps to train.')\n",
        "tf.flags.DEFINE_string('model', 'baseline',\n",
        "                       'The model to use for the experiment.'\n",
        "                       'capsule or baseline')\n",
        "tf.flags.DEFINE_string('dataset', 'mnist',\n",
        "                       'The dataset to use for the experiment.'\n",
        "                       'mnist, norb, cifar10.')\n",
        "tf.flags.DEFINE_integer('num_gpus', 1, 'Number of gpus to use.')\n",
        "tf.flags.DEFINE_integer('num_targets', 1,\n",
        "                        'Number of targets to detect (1 or 2).')\n",
        "tf.flags.DEFINE_integer('num_trials', 1,\n",
        "                        'Number of trials for ensemble evaluation.')\n",
        "tf.flags.DEFINE_integer('save_step', 1500, 'How often to save checkpoints.')\n",
        "tf.flags.DEFINE_string('summary_dir', 'tmp3',\n",
        "                       'Main directory for the experiments.')\n",
        "tf.flags.DEFINE_string('checkpoint', 'tmp/train/model.ckpt-24000',\n",
        "                       'The model checkpoint for evaluation.')\n",
        "#tf.flags.DEFINE_string('checkpoint', 'mnist_checkpoint/model.ckpt-1',\n",
        "#                      'The model checkpoint for evaluation.')\n",
        "tf.flags.DEFINE_bool('train', True, 'Either train the model or test the model.')\n",
        "tf.flags.DEFINE_bool('validate', False, 'Run training/eval in validation mode.')\n",
        "\n",
        "\n",
        "\n",
        "models = {\n",
        "    'capsule': capsule_model.CapsuleModel,\n",
        "    'baseline': conv_model.ConvModel,\n",
        "}\n",
        "\n",
        "\n",
        "def get_features(split, total_batch_size, num_gpus, data_dir, num_targets,\n",
        "                 dataset, validate=False):\n",
        "  \"\"\"Reads the input data and distributes it over num_gpus GPUs.\n",
        "\n",
        "  Each tower of data has 1/FLAGS.num_gpus of the total_batch_size.\n",
        "\n",
        "  Args:\n",
        "    split: 'train' or 'test', split of the data to read.\n",
        "    total_batch_size: total number of data entries over all towers.\n",
        "    num_gpus: Number of GPUs to distribute the data on.\n",
        "    data_dir: Directory containing the input data.\n",
        "    num_targets: Number of objects present in the image.\n",
        "    dataset: The name of the dataset, either norb or mnist.\n",
        "    validate: If set, subset training data into training and test.\n",
        "\n",
        "  Returns:\n",
        "    A list of batched feature dictionaries.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If dataset is not mnist or norb.\n",
        "  \"\"\"\n",
        "\n",
        "  batch_size = total_batch_size // max(1, num_gpus)\n",
        "  features = []\n",
        "  for i in range(num_gpus):\n",
        "    with tf.device('/gpu:%d' % i):\n",
        "      if dataset == 'mnist':\n",
        "        features.append(\n",
        "            mnist_input_record.inputs(\n",
        "                data_dir=data_dir,\n",
        "                batch_size=batch_size,\n",
        "                split=split,\n",
        "                num_targets=num_targets,\n",
        "                validate=validate,\n",
        "            ))\n",
        "      elif dataset == 'norb':\n",
        "        features.append(\n",
        "            norb_input_record.inputs(\n",
        "                data_dir=data_dir, batch_size=batch_size, split=split,\n",
        "            ))\n",
        "      elif dataset == 'cifar10':\n",
        "        data_dir = os.path.join(data_dir, 'cifar-10-batches-bin')\n",
        "        features.append(\n",
        "            cifar10_input.inputs(\n",
        "                split=split, data_dir=data_dir, batch_size=batch_size))\n",
        "      else:\n",
        "        raise ValueError(\n",
        "            'Unexpected dataset {!r}, must be mnist, norb, or cifar10.'.format(\n",
        "                dataset))\n",
        "  return features\n",
        "\n",
        "\n",
        "def extract_step(path):\n",
        "  \"\"\"Returns the step from the file format name of Tensorflow checkpoints.\n",
        "\n",
        "  Args:\n",
        "    path: The checkpoint path returned by tf.train.get_checkpoint_state.\n",
        "      The format is: {ckpnt_name}-{step}\n",
        "\n",
        "  Returns:\n",
        "    The last training step number of the checkpoint.\n",
        "  \"\"\"\n",
        "  file_name = os.path.basename(path)\n",
        "  return int(file_name.split('-')[-1])\n",
        "\n",
        "\n",
        "def load_training(saver, session, load_dir):\n",
        "  \"\"\"Loads a saved model into current session or initializes the directory.\n",
        "\n",
        "  If there is no functioning saved model or FLAGS.restart is set, cleans the\n",
        "  load_dir directory. Otherwise, loads the latest saved checkpoint in load_dir\n",
        "  to session.\n",
        "\n",
        "  Args:\n",
        "    saver: An instance of tf.train.saver to load the model in to the session.\n",
        "    session: An instance of tf.Session with the built-in model graph.\n",
        "    load_dir: The directory which is used to load the latest checkpoint.\n",
        "\n",
        "  Returns:\n",
        "    The latest saved step.\n",
        "  \"\"\"\n",
        "  if tf.gfile.Exists(load_dir):\n",
        "    ckpt = tf.train.get_checkpoint_state(load_dir)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "      saver.restore(session, ckpt.model_checkpoint_path)\n",
        "      prev_step = extract_step(ckpt.model_checkpoint_path)\n",
        "    else:\n",
        "      tf.gfile.DeleteRecursively(load_dir)\n",
        "      tf.gfile.MakeDirs(load_dir)\n",
        "      prev_step = 0\n",
        "  else:\n",
        "    tf.gfile.MakeDirs(load_dir)\n",
        "    prev_step = 0\n",
        "  return prev_step\n",
        "\n",
        "\n",
        "def train_experiment(session, result, writer, last_step, max_steps, saver,\n",
        "                     summary_dir, save_step):\n",
        "  \"\"\"Runs training for up to max_steps and saves the model and summaries.\n",
        "\n",
        "  Args:\n",
        "    session: The loaded tf.session with the initialized model.\n",
        "    result: The resultant operations of the model including train_op.\n",
        "    writer: The summary writer file.\n",
        "    last_step: The last trained step.\n",
        "    max_steps: Maximum number of training iterations.\n",
        "    saver: An instance of tf.train.saver to save the current model.\n",
        "    summary_dir: The directory to save the model in it.\n",
        "    save_step: How often to save the model ckpt.\n",
        "  \"\"\"\n",
        "  step = 0\n",
        "  for i in tqdm(range(last_step, max_steps)):\n",
        "    step += 1\n",
        "    summary, _ = session.run([result.summary, result.train_op])\n",
        "    writer.add_summary(summary, i)\n",
        "    if (i + 1) % save_step == 0:\n",
        "      saver.save(\n",
        "          session, os.path.join(summary_dir, 'model.ckpt'), global_step=i + 1)\n",
        "\n",
        "\n",
        "def load_eval(saver, session, load_dir):\n",
        "  \"\"\"Loads the latest saved model to the given session.\n",
        "\n",
        "  Args:\n",
        "    saver: An instance of tf.train.saver to load the model in to the session.\n",
        "    session: An instance of tf.Session with the built-in model graph.\n",
        "    load_dir: The path to the latest checkpoint.\n",
        "\n",
        "  Returns:\n",
        "    The latest saved step.\n",
        "  \"\"\"\n",
        "  saver.restore(session, load_dir)\n",
        "  print('model loaded successfully')\n",
        "  return extract_step(load_dir)\n",
        "\n",
        "\n",
        "def eval_experiment(session, result, writer, last_step, max_steps, **kwargs):\n",
        "  \"\"\"Evaluates the current model on the test dataset once.\n",
        "\n",
        "  Evaluates the loaded model on the test data set with batch sizes of 100.\n",
        "  Aggregates the results and writes one summary point to the summary file.\n",
        "\n",
        "  Args:\n",
        "    session: The loaded tf.session with the trained model.\n",
        "    result: The resultant operations of the model including evaluation metrics.\n",
        "    writer: The summary writer file.\n",
        "    last_step: The last trained step.\n",
        "    max_steps: Maximum number of evaluation iterations.\n",
        "    **kwargs: Arguments passed by run_experiment but not used in this function.\n",
        "  \"\"\"\n",
        "  del kwargs\n",
        "\n",
        "  total_correct = 0\n",
        "  total_almost = 0\n",
        "  for _ in tqdm(range(max_steps)):\n",
        "    summary_i, correct, almost = session.run(\n",
        "        [result.summary, result.correct, result.almost])\n",
        "    total_correct += correct\n",
        "    total_almost += almost\n",
        "    print(total_correct)\n",
        "  total_false = max_steps * 100 - total_correct\n",
        "  total_almost_false = max_steps * 100 - total_almost\n",
        "  summary = tf.Summary.FromString(summary_i)\n",
        "  summary.value.add(tag='correct_prediction', simple_value=total_correct)\n",
        "  summary.value.add(tag='wrong_prediction', simple_value=total_false)\n",
        "  summary.value.add(\n",
        "      tag='almost_wrong_prediction', simple_value=total_almost_false)\n",
        "  print('Total wrong predictions: {}, wrong percent: {}%'.format(\n",
        "      total_false, total_false / max_steps))\n",
        "  tf.logging.info('Total wrong predictions: {}, wrong percent: {}%'.format(\n",
        "      total_false, total_false / max_steps))\n",
        "  writer.add_summary(summary, last_step)\n",
        "\n",
        "\n",
        "def run_experiment(loader,\n",
        "                   load_dir,\n",
        "                   writer,\n",
        "                   experiment,\n",
        "                   result,\n",
        "                   max_steps,\n",
        "                   save_step=0):\n",
        "  \"\"\"Starts a session, loads the model and runs the given experiment on it.\n",
        "\n",
        "  This is a general wrapper to load a saved model and run an experiment on it.\n",
        "  An experiment can be a training experiment or an evaluation experiment.\n",
        "  It starts session, threads and queues and closes them before returning.\n",
        "\n",
        "  Args:\n",
        "    loader: A function of prototype (saver, session, load_dir) to load a saved\n",
        "      checkpoint in load_dir given a session and saver.\n",
        "    load_dir: The directory to load the previously saved model from it and to\n",
        "      save the current model in it.\n",
        "    writer: A tf.summary.FileWriter to add summaries.\n",
        "    experiment: The function of prototype (session, result, writer, last_step,\n",
        "      max_steps, saver, load_dir, save_step) which will execute the experiment\n",
        "      steps from result on the given session.\n",
        "    result: The resultant final operations of the built model.\n",
        "    max_steps: Maximum number of experiment iterations.\n",
        "    save_step: How often the training model should be saved.\n",
        "  \"\"\"\n",
        "  config = tf.ConfigProto(allow_soft_placement=True)\n",
        "  config.gpu_options.allow_growth=True\n",
        "  session = tf.Session(config=config)\n",
        "  init_op = tf.group(tf.global_variables_initializer(),\n",
        "                     tf.local_variables_initializer())\n",
        "  session.run(init_op)\n",
        "  saver = tf.train.Saver(max_to_keep=1000)\n",
        "  last_step = loader(saver, session, load_dir)\n",
        "  coord = tf.train.Coordinator()\n",
        "  threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
        "  try:\n",
        "    experiment(\n",
        "        session=session,\n",
        "        result=result,\n",
        "        writer=writer,\n",
        "        last_step=last_step,\n",
        "        max_steps=max_steps,\n",
        "        saver=saver,\n",
        "        summary_dir=load_dir,\n",
        "        save_step=save_step)\n",
        "  except tf.errors.OutOfRangeError:\n",
        "    tf.logging.info('Finished experiment.')\n",
        "  finally:\n",
        "    coord.request_stop()\n",
        "  coord.join(threads)\n",
        "  session.close()\n",
        "\n",
        "\n",
        "def train(hparams, summary_dir, num_gpus, model_type, max_steps, save_step,\n",
        "          data_dir, num_targets, dataset, validate):\n",
        "  \"\"\"Trains a model with batch sizes of 128 to FLAGS.max_steps steps.\n",
        "\n",
        "  It will initialize the model with either previously saved model in the\n",
        "  summary directory or start from scratch if FLAGS.restart is set or the\n",
        "  directory is empty.\n",
        "  The training is distributed on num_gpus GPUs. It writes a summary at every\n",
        "  step and saves the model every 1500 iterations.\n",
        "\n",
        "  Args:\n",
        "    hparams: The hyper parameters to build the model graph.\n",
        "    summary_dir: The directory to save model and write training summaries.\n",
        "    num_gpus: Number of GPUs to use for reading data and computation.\n",
        "    model_type: The model architecture category.\n",
        "    max_steps: Maximum number of training iterations.\n",
        "    save_step: How often the training model should be saved.\n",
        "    data_dir: Directory containing the input data.\n",
        "    num_targets: Number of objects present in the image.\n",
        "    dataset: Name of the dataset for the experiments.\n",
        "    validate: If set, use training-validation set for training.\n",
        "  \"\"\"\n",
        "  summary_dir += '/train/'\n",
        "  with tf.Graph().as_default():\n",
        "    # Build model\n",
        "    features = get_features('train', 128, num_gpus, data_dir, num_targets,\n",
        "                            dataset, validate)\n",
        "    model = models[model_type](hparams)\n",
        "    result, _ = model.multi_gpu(features, num_gpus)\n",
        "    # Print stats\n",
        "    param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
        "        tf.get_default_graph(),\n",
        "        tfprof_options=tf.contrib.tfprof.model_analyzer.\n",
        "        TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
        "    sys.stdout.write('total_params: %d\\n' % param_stats.total_parameters)\n",
        "    \"\"\"\n",
        "    total_parameters = 0\n",
        "    for ariable in tf.trainable_variables():\n",
        "      local_parameters=1\n",
        "      shape = variable.get_shape()\n",
        "      for i in shape:\n",
        "        print(shape)\n",
        "        local_parameters*=i.values\n",
        "        total_parameters+=local_parameters\n",
        "    print(total)\n",
        "    \"\"\"\n",
        "    writer = tf.summary.FileWriter(summary_dir)\n",
        "    run_experiment(load_training, summary_dir, writer, train_experiment, result,\n",
        "                   max_steps, save_step)\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def find_checkpoint(load_dir, seen_step):\n",
        "  \"\"\"Finds the global step for the latest written checkpoint to the load_dir.\n",
        "\n",
        "  Args:\n",
        "    load_dir: The directory address to look for the training checkpoints.\n",
        "    seen_step: Latest step which evaluation has been done on it.\n",
        "  Returns:\n",
        "    The latest new step in the load_dir and the file path of the latest model\n",
        "    in load_dir. If no new file is found returns -1 and None.\n",
        "\n",
        "  \"\"\"\n",
        "  ckpt = tf.train.get_checkpoint_state(load_dir)\n",
        "  if ckpt and ckpt.model_checkpoint_path:\n",
        "    global_step = extract_step(ckpt.model_checkpoint_path)\n",
        "    if int(global_step) != seen_step:\n",
        "      return int(global_step), ckpt.model_checkpoint_path\n",
        "  return -1, None\n",
        "\n",
        "\n",
        "def evaluate(hparams, summary_dir, num_gpus, model_type, eval_size, data_dir,\n",
        "             num_targets, dataset, validate, checkpoint=None):\n",
        "  \"\"\"Continuously evaluates the latest trained model or a specific checkpoint.\n",
        "\n",
        "  Regularly (every 2 min, maximum 6 hours) checks the training directory for\n",
        "  the latest model. If it finds any new model, it outputs the total number of\n",
        "  correct and wrong predictions for the test data set to the summary file.\n",
        "  If a checkpoint is provided performs the evaluation only on the specific\n",
        "  checkpoint.\n",
        "\n",
        "  Args:\n",
        "    hparams: The hyperparameters for building the model graph.\n",
        "    summary_dir: The directory to load training model and write test summaries.\n",
        "    num_gpus: Number of GPUs to use for reading data and computation.\n",
        "    model_type: The model architecture category.\n",
        "    eval_size: Total number of examples in the test dataset.\n",
        "    data_dir: Directory containing the input data.\n",
        "    num_targets: Number of objects present in the image.\n",
        "    dataset: The name of the dataset for the experiment.\n",
        "    validate: If set, use validation set for continuous evaluation.\n",
        "    checkpoint: (optional) The checkpoint file name.\n",
        "  \"\"\"\n",
        "  load_dir = summary_dir + '/train/'\n",
        "  summary_dir += '/test/'\n",
        "  with tf.Graph().as_default():\n",
        "    features = get_features('test', 100, num_gpus, data_dir, num_targets,\n",
        "                            dataset, validate)\n",
        "    model = models[model_type](hparams)\n",
        "    result, _ = model.multi_gpu(features, num_gpus)\n",
        "    test_writer = tf.summary.FileWriter(summary_dir)\n",
        "    seen_step = -1\n",
        "    paused = 0\n",
        "    while paused < 360:\n",
        "      print('start evaluation, model defined')\n",
        "      if checkpoint:\n",
        "        step = extract_step(checkpoint)\n",
        "        last_checkpoint = checkpoint\n",
        "      else:\n",
        "        step, last_checkpoint = find_checkpoint(load_dir, seen_step)\n",
        "      if step == -1:\n",
        "        time.sleep(60)\n",
        "        paused += 1\n",
        "      else:\n",
        "        paused = 0\n",
        "        seen_step = step\n",
        "        run_experiment(load_eval, last_checkpoint, test_writer, eval_experiment,\n",
        "                       result, eval_size // 100)\n",
        "   #     run_experiment(load_eval, last_checkpoint, test_writer, eval_experiment,\n",
        "   #                    result, eval_size)\n",
        "        if checkpoint:\n",
        "          break\n",
        "\n",
        "    test_writer.close()\n",
        "\n",
        "\n",
        "def get_placeholder_data(num_steps, batch_size, features, session):\n",
        "  \"\"\"Reads the features into a numpy array and replaces them with placeholders.\n",
        "\n",
        "  Loads all the images and labels of the features queue in memory. Replaces\n",
        "  the feature queue reader handle with placeholders to switch input method from\n",
        "  queue to placeholders. Using placeholders gaurantees the order of datapoints\n",
        "  to stay exactly the same during each epoch.\n",
        "\n",
        "  Args:\n",
        "    num_steps: The number of times to read from the features queue.\n",
        "    batch_size: The number of datapoints at each step.\n",
        "    features: The dictionary containing the data queues such as images.\n",
        "    session: The session handle to use for running tensors.\n",
        "\n",
        "  Returns:\n",
        "    data: List of numpy arrays containing all the queued data in features.\n",
        "    targets: List of all the labels in range [0...num_classes].\n",
        "  \"\"\"\n",
        "  image_size = features['height']\n",
        "  depth = features['depth']\n",
        "  print(\"depth value :\"+depth)\n",
        "  num_classes = features['num_classes']\n",
        "  data = []\n",
        "  targets = []\n",
        "  for i in range(num_steps):\n",
        "    data.append(\n",
        "        session.run({\n",
        "            'recons_label': features['recons_label'],\n",
        "            'labels': features['labels'],\n",
        "            'images': features['images'],\n",
        "            'recons_image': features['recons_image']\n",
        "        }))\n",
        "    targets.append(data[i]['recons_label'])\n",
        "  image_shape = (batch_size, depth, image_size, image_size)\n",
        "  features['images'] = tf.placeholder(tf.float32, shape=image_shape)\n",
        "  features['labels'] = tf.placeholder(\n",
        "      tf.float32, shape=(batch_size, num_classes))\n",
        "  features['recons_image'] = tf.placeholder(tf.float32, shape=image_shape)\n",
        "  features['recons_label'] = tf.placeholder(tf.int32, shape=(batch_size))\n",
        "  return data, targets\n",
        "\n",
        "\n",
        "def infer_ensemble_logits(features, model, checkpoints, session, num_steps,\n",
        "                          data):\n",
        "  \"\"\"Extracts the logits for the whole dataset and all the trained models.\n",
        "\n",
        "  Loads all the checkpoints. For each checkpoint stores the logits for the whole\n",
        "  dataset.\n",
        "\n",
        "  Args:\n",
        "    features: The dictionary of the input handles.\n",
        "    model: The model operation graph.\n",
        "    checkpoints: The list of all checkpoint paths.\n",
        "    session: The session handle to use for running tensors.\n",
        "    num_steps: The number of steps to run the experiment.\n",
        "    data: The num_steps list of loaded data to be fed to placeholders.\n",
        "\n",
        "  Returns:\n",
        "    logits: List of all the final layer logits for different checkpoints.\n",
        "  \"\"\"\n",
        "  _, inferred = model.multi_gpu([features], 1)\n",
        "  logits = []\n",
        "  saver = tf.train.Saver()\n",
        "  for checkpoint in checkpoints:\n",
        "    saver.restore(session, checkpoint)\n",
        "    for i in range(num_steps):\n",
        "      logits.append(\n",
        "          session.run(\n",
        "              inferred[0].logits,\n",
        "              feed_dict={\n",
        "                  features['recons_label']: data[i]['recons_label'],\n",
        "                  features['labels']: data[i]['labels'],\n",
        "                  features['images']: data[i]['images'],\n",
        "                  features['recons_image']: data[i]['recons_image']\n",
        "              }))\n",
        "  return logits\n",
        "\n",
        "\n",
        "def evaluate_ensemble(hparams, model_type, eval_size, data_dir, num_targets,\n",
        "                      dataset, checkpoint, num_trials):\n",
        "  \"\"\"Evaluates an ensemble of trained models.\n",
        "\n",
        "  Loads a series of checkpoints and aggregates the output logit of them on the\n",
        "  test data. Selects the class with maximum aggregated logit as the prediction.\n",
        "  Prints the total number of wrong predictions.\n",
        "\n",
        "  Args:\n",
        "    hparams: The hyperparameters for building the model graph.\n",
        "    model_type: The model architecture category.\n",
        "    eval_size: Total number of examples in the test dataset.\n",
        "    data_dir: Directory containing the input data.\n",
        "    num_targets: Number of objects present in the image.\n",
        "    dataset: The name of the dataset for the experiment.\n",
        "    checkpoint: The file format of the checkpoints to be loaded.\n",
        "    num_trials: Number of trained models to ensemble.\n",
        "  \"\"\"\n",
        "  checkpoints = []\n",
        "  for i in range(num_trials):\n",
        "    file_name = checkpoint.format(i)\n",
        "    if tf.train.checkpoint_exists(file_name):\n",
        "      checkpoints.append(file_name)\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    batch_size = 100\n",
        "    features = get_features('test', batch_size, 1, data_dir, num_targets,\n",
        "                            dataset)[0]\n",
        "    model = models[model_type](hparams)\n",
        "\n",
        "    config = tf.ConfigProto(allow_soft_placement=True)\n",
        "    config.gpu_options.allow_growth=True\n",
        "    session = tf.Session(config=config)\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
        "    num_steps = eval_size // batch_size\n",
        "    data, targets = get_placeholder_data(num_steps, batch_size, features,\n",
        "                                         session)\n",
        "    logits = infer_ensemble_logits(features, model, checkpoints, session,\n",
        "                                   num_steps, data)\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n",
        "    session.close()\n",
        "\n",
        "    logits = np.reshape(logits, (num_trials, num_steps, batch_size, -1))\n",
        "    logits = np.sum(logits, axis=0)\n",
        "    predictions = np.argmax(logits, axis=2)\n",
        "    total_wrong = np.sum(np.not_equal(predictions, targets))\n",
        "    print('Total wrooong predictions: {}, wrong percent: {}%'.format(\n",
        "        total_wrong, total_wrong / eval_size * 100))\n",
        "\n",
        "\n",
        "def default_hparams():\n",
        "  \"\"\"Builds an HParam object with default hyperparameters.\"\"\"\n",
        "  return tf.contrib.training.HParams(\n",
        "      decay_rate=0.96,\n",
        "      decay_steps=2000,\n",
        "      leaky=False,\n",
        "      learning_rate=0.001,\n",
        "      loss_type='margin',\n",
        "      num_prime_capsules=32,\n",
        "      padding='VALID',\n",
        "      remake=True,\n",
        "      routing=3,\n",
        "      verbose=False,\n",
        "  )\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  hparams = default_hparams()\n",
        "  if FLAGS.hparams_override:\n",
        "    hparams.parse(FLAGS.hparams_override)\n",
        "\n",
        "  if FLAGS.train:\n",
        "    train(hparams, FLAGS.summary_dir, FLAGS.num_gpus, FLAGS.model,\n",
        "          FLAGS.max_steps, FLAGS.save_step, FLAGS.data_dir, FLAGS.num_targets,\n",
        "          FLAGS.dataset, FLAGS.validate)\n",
        "  else:\n",
        "    if FLAGS.num_trials == 1:\n",
        "      evaluate(hparams, FLAGS.summary_dir, FLAGS.num_gpus, FLAGS.model,\n",
        "               FLAGS.eval_size, FLAGS.data_dir, FLAGS.num_targets,\n",
        "               FLAGS.dataset, FLAGS.validate, FLAGS.checkpoint)\n",
        "    else:\n",
        "      evaluate_ensemble(hparams, FLAGS.model, FLAGS.eval_size, FLAGS.data_dir,\n",
        "                        FLAGS.num_targets, FLAGS.dataset, FLAGS.checkpoint,\n",
        "                        FLAGS.num_trials)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting experiment.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr5owh57dHEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python experiment.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJjwAyThnYK1",
        "colab_type": "code",
        "outputId": "642cc5ea-58f0-481f-e282-486359b0e3f2",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title ModifiedMnistLoader\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "def load_modified_mnist():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_trainModified=np.zeros((60000,28,28,3),dtype=int)\n",
        "    for x in range(x_train.shape[0]):\n",
        "      x_trainModified[x] = cv2.cvtColor(x_train[x],cv2.COLOR_GRAY2RGB)\n",
        "    x_testModified=np.zeros((10000,28,28,3),dtype=int)\n",
        "    for x in range(x_test.shape[0]):\n",
        "      x_testModified[x] = cv2.cvtColor(x_test[x],cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    !wget \"https://images2.alphacoders.com/101/1011957.jpg\"\n",
        "    sourceImage = mpimg.imread('1011957.jpg')\n",
        "\n",
        "    sourceWidth = sourceImage.shape[1]\n",
        "    sourceHeight = sourceImage.shape[0]\n",
        "    width = 28\n",
        "    height = 28\n",
        "\n",
        "    for x in range(60000):\n",
        "     x1 = random.randint(0, sourceWidth-width-1)\n",
        "     y1 = random.randint(0, sourceHeight-height-1)\n",
        "     croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "     for row in range(x_trainModified[x].shape[0]):\n",
        "        for pixel in range(x_trainModified[x].shape[1]):\n",
        "         if all(i<140 for i in x_trainModified[x][row][pixel]):\n",
        "           x_trainModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "\n",
        "    for x in range(10000):\n",
        "      x1 = random.randint(0, sourceWidth-width-1)\n",
        "      y1 = random.randint(0, sourceHeight-height-1)\n",
        "      croppedImage= sourceImage[y1:y1+height,x1:x1+width,:]\n",
        "      for row in range(x_testModified[x].shape[0]):\n",
        "        for pixel in range(x_testModified[x].shape[1]):\n",
        "          if all(i<140 for i in x_testModified[x][row][pixel]):\n",
        "            x_testModified[x][row][pixel]=croppedImage[row][pixel]\n",
        "    \n",
        "    x_trainModified = x_trainModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "    x_testModified = x_testModified.reshape(-1, 28, 28, 3).astype('float32') / 255.\n",
        "  #  y_train = to_categorical(y_train.astype('float32'))\n",
        "  #  y_test = to_categorical(y_test.astype('float32'))\n",
        "    return (x_trainModified, y_train), (x_testModified, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eHzO24FnEDR",
        "colab_type": "text"
      },
      "source": [
        "## Creating TF records MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEcD15r5jvbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gzip\n",
        "import os\n",
        "\n",
        "import numpy\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZJnDKZ8nR2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {}\n",
        "params['download_data_location'] = 'mnist_data/'\n",
        "params['tfrecord_location'] = 'mnist_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-U4mkqxnpi5",
        "colab_type": "code",
        "outputId": "09e7444e-93a4-4b2f-d92b-8d137ea2ee14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "directory = params['download_data_location']\n",
        "(train_images, train_labels), (test_images, test_labels) = load_modified_mnist()  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "11501568/11490434 [==============================] - 2s 0us/step\n",
            "--2019-11-20 12:21:54--  https://images2.alphacoders.com/101/1011957.jpg\n",
            "Resolving images2.alphacoders.com (images2.alphacoders.com)... 104.20.15.194, 104.20.14.194, 2606:4700:10::6814:fc2, ...\n",
            "Connecting to images2.alphacoders.com (images2.alphacoders.com)|104.20.15.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4390417 (4.2M) [image/jpeg]\n",
            "Saving to: ‘1011957.jpg’\n",
            "\n",
            "1011957.jpg         100%[===================>]   4.19M  2.77MB/s    in 1.5s    \n",
            "\n",
            "2019-11-20 12:21:57 (2.77 MB/s) - ‘1011957.jpg’ saved [4390417/4390417]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w97HAWQEpJVG",
        "colab_type": "code",
        "outputId": "1a43a77c-1744-495b-b1ed-acdc9b5bc06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1011957.jpg\t\tinput_data\t\t  mnist_data.tar.gz  testdata\n",
            "cifar-10-binary.tar.gz\tmnist_checkpoints.tar.gz  models\n",
            "experiment.py\t\tmnist_data\t\t  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWeCg5hioAHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile.MakeDirs(directory)\n",
        "name = \"train_2shifted_mnist.tfrecords\"\n",
        "filename = os.path.join(params['tfrecord_location'], name)\n",
        "tfrecord_writer = tf.python_io.TFRecordWriter(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF4sQdLYoKew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybqeZO76xRmc",
        "colab_type": "code",
        "outputId": "1a558162-c87b-4cc2-a206-5b999d85647a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGnPH1fQoNBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_examples = train_images.shape[0]\n",
        "images = train_images\n",
        "labels = train_labels\n",
        "\n",
        "rows = images.shape[1]\n",
        "cols = images.shape[2]\n",
        "depth = images.shape[3]\n",
        "  \n",
        "for index in range(num_examples):\n",
        "  # 1. Convert your data into tf.train.Feature\n",
        "  image_raw = images[index].tostring()\n",
        "  feature = {\n",
        "    'height': _int64_feature(rows),\n",
        "    'width': _int64_feature(cols),\n",
        "    'depth': _int64_feature(depth),\n",
        "    'label': _int64_feature(labels[index]),\n",
        "    'image_raw': _bytes_feature(image_raw)\n",
        "  }\n",
        "  # 2. Create a tf.train.Features\n",
        "  features = tf.train.Features(feature=feature)\n",
        "  # 3. Createan example protocol\n",
        "  example = tf.train.Example(features=features)\n",
        "  # 4. Serialize the Example to string\n",
        "  example_to_string = example.SerializeToString()\n",
        "  # 5. Write to TFRecord\n",
        "  tfrecord_writer.write(example_to_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kQ_BXWbAdnY",
        "colab_type": "code",
        "outputId": "5e482cbb-451b-469a-f051-2129e97d59bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/capsule-model-forked-from-Sarasra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxpqotRlAur_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -r mnist_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32K97NAT4TD0",
        "colab_type": "code",
        "outputId": "d3696c46-8b16-400e-f740-5db4b4e0a191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_2shifted_mnist.tfrecords\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHSraGcSxuJm",
        "colab_type": "code",
        "outputId": "fdcd8b46-3b2c-48f9-cb32-9242a5d1e99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd mnist_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/capsule-model-forked-from-Sarasra/mnist_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Lvu26awD7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_format = '{}_{}shifted_mnist.tfrecords'\n",
        "data_dir='mnist_data'\n",
        "split = 'train'\n",
        "shift = 2\n",
        "filenames = [os.path.join(data_dir, file_format.format(split, shift))]\n",
        "with tf.name_scope('input'):\n",
        "  filename_queue = tf.train.string_input_producer(\n",
        "      filenames, shuffle=(split == 'train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8cy4kh-vd1n",
        "colab_type": "code",
        "outputId": "bf0b3741-9b4d-4ebd-bad4-b430a191d70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "reader = tf.TFRecordReader()\n",
        "_, serialized_example = reader.read(filename_queue)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1120 12:28:17.955873 139805621323648 deprecation.py:323] From <ipython-input-35-201f3492d706>:1: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COPjGKodypwL",
        "colab_type": "code",
        "outputId": "86322d9d-0537-41b6-8727-df0517643fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "# Convert to Examples and write the result to TFRecord files.\n",
        "convert_and_save_to(train_images, train_labels, 'train', params)\n",
        "convert_and_save_to(test_images, test_labels, 'test', params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7eed1e1e7a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvert_and_save_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconvert_and_save_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'convert_and_save_to' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0qU55LEhGS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKKIM9BqxXEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features={\n",
        "          'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "          'label': tf.FixedLenFeature([], tf.int64),\n",
        "          'height': tf.FixedLenFeature([], tf.int64),\n",
        "          'width': tf.FixedLenFeature([], tf.int64),\n",
        "          'depth': tf.FixedLenFeature([], tf.int64)\n",
        "      })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2k9IQPlnQqK",
        "colab_type": "text"
      },
      "source": [
        "## Files copied to Ipython notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZSb0uVd1Q71",
        "colab_type": "code",
        "outputId": "815e2e42-b139-41be-8181-e0031a8c66bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Tests for conv_model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class ConvModelTest(tf.test.TestCase):\n",
        "\n",
        "  def setUp(self):\n",
        "    self.hparams = tf.contrib.training.HParams(\n",
        "        learning_rate=0.001,\n",
        "        decay_rate=0.96,\n",
        "        decay_steps=1,\n",
        "        padding='SAME',\n",
        "        verbose=False,\n",
        "        loss_type='softmax')\n",
        "\n",
        "  def testIntegrity(self):\n",
        "    \"\"\"Checks a multi_gpu call on ConvModel builds the desired graph.\n",
        "\n",
        "    With the correct inference graph, multi_gpu is able to call inference\n",
        "    multiple times without any increase in number of trainable variables or a\n",
        "    duplication error. Each tower should have 4 set of (weight, bias) variable.\n",
        "    \"\"\"\n",
        "    with tf.Graph().as_default():\n",
        "      test_model = conv_model.ConvModel(self.hparams)\n",
        "      toy_image = np.reshape(np.arange(32 * 32), (1, 1, 32, 32))\n",
        "      input_image = tf.constant(toy_image, dtype=tf.float32)\n",
        "      features = {\n",
        "          'height': 32,\n",
        "          'depth': 1,\n",
        "          'images': input_image,\n",
        "          'labels': tf.one_hot([2], 10),\n",
        "          'num_targets': 1,\n",
        "          'num_classes': 10,\n",
        "      }\n",
        "      _, tower_output = test_model.multi_gpu([features, features, features], 3)\n",
        "      trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
        "      self.assertEqual(len(trainable_vars), 8)\n",
        "      _, classes = tower_output[0].logits.get_shape()\n",
        "      self.assertEqual(10, classes.value)\n",
        "\n",
        "\n",
        "\n",
        "tf.test.main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running tests under Python 2.7.15: /usr/bin/python2\n",
            "W1120 12:17:06.898376 139805621323648 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/tensorflow_estimator/python/estimator/api/_v1/estimator/__init__.py:12: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "UnrecognizedFlagError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mUnrecognizedFlagError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-413b95f728cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/test.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;34m\"\"\"Runs all unit tests.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0m_test_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstallStackTraceHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_googletest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/googletest.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_main\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/benchmark.pyc\u001b[0m in \u001b[0;36mbenchmarks_main\u001b[0;34m(true_main, argv)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_run_benchmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mtrue_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/googletest.pyc\u001b[0m in \u001b[0;36mmain_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_main\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/app.pyc\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/googletest.pyc\u001b[0m in \u001b[0;36mg_main\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;34m\"\"\"Delegate to absltest.main.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mabsltest_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/testing/absltest.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m   \"\"\"\n\u001b[1;32m   1854\u001b[0m   \u001b[0mprint_python_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m   \u001b[0m_run_in_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/testing/absltest.pyc\u001b[0m in \u001b[0;36m_run_in_app\u001b[0;34m(function, args, kwargs)\u001b[0m\n\u001b[1;32m   1956\u001b[0m     \u001b[0;31m# after the command-line has been parsed. So we have the for loop below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m     \u001b[0;31m# to change back flags to their old values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m     \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msaved_flag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       \u001b[0msaved_flag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/absl/flags/_flagvalues.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0msuggestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flag_suggestions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       raise _exceptions.UnrecognizedFlagError(\n\u001b[0;32m--> 633\u001b[0;31m           name, value, suggestions=suggestions)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnrecognizedFlagError\u001b[0m: Unknown command line flag 'f'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3dhpdEq1eG1",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "bb0b8290-78f4-4262-9afe-9fb322ffd38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title conv_model.py\n",
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Convolutional Model class.\n",
        "\n",
        "Uses only convolutional and fully connected layers for the inference ops.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class ConvModel(model.Model):\n",
        "  \"\"\"A baseline multi GPU Model without capsule layers.\n",
        "\n",
        "  The inference graph includes ReLU convolution layers and fully connected\n",
        "  layers. The last layer is linear and has 10 units.\n",
        "  \"\"\"\n",
        "\n",
        "  def _add_convs(self, input_tensor, channels):\n",
        "    \"\"\"Adds the convolution layers.\n",
        "\n",
        "    Adds a series of convolution layers with ReLU nonlinearity and pooling\n",
        "    after each of them.\n",
        "\n",
        "    Args:\n",
        "      input_tensor: a 4D float tensor as the input to the first convolution.\n",
        "      channels: A list of channel sizes for input_tensor and following\n",
        "        convolution layers. Number of channels in input tensor should be\n",
        "        equal to channels[0].\n",
        "    Returns:\n",
        "      A 4D tensor as the output of the last pooling layer.\n",
        "    \"\"\"\n",
        "    for i in xrange(1, len(channels)):\n",
        "      with tf.variable_scope('conv{}'.format(i)) as scope:\n",
        "        kernel = variables.weight_variable(\n",
        "            shape=[5, 5, channels[i - 1], channels[i]], stddev=5e-2,\n",
        "            verbose=self._hparams.verbose\n",
        "        )\n",
        "        conv = tf.nn.conv2d(\n",
        "            input_tensor,\n",
        "            kernel, [1, 1, 1, 1],\n",
        "            padding=self._hparams.padding,\n",
        "            data_format='NCHW')\n",
        "        biases = variables.bias_variable([channels[i]],\n",
        "                                         verbose=self._hparams.verbose)\n",
        "        pre_activation = tf.nn.bias_add(conv, biases, data_format='NCHW')\n",
        "        relu = tf.nn.relu(pre_activation, name=scope.name)\n",
        "        if self._hparams.verbose:\n",
        "          tf.summary.histogram('activation', relu)\n",
        "        input_tensor = tf.contrib.layers.max_pool2d(\n",
        "            relu, kernel_size=2, stride=2, data_format='NCHW', padding='SAME')\n",
        "\n",
        "    return input_tensor\n",
        "\n",
        "  def inference(self, features):\n",
        "    \"\"\"Adds the inference graph ops.\n",
        "\n",
        "    Builds the architecture of the neural net to drive logits from features.\n",
        "    The inference graph includes a series of convolution and fully connected\n",
        "    layers and outputs a [batch, 10] tensor as the logits.\n",
        "\n",
        "    Args:\n",
        "      features: Dictionary of batched feature tensors like images and labels.\n",
        "    Returns:\n",
        "      A model.Inferred named tuple of expected outputs of the model like\n",
        "      'logits' and 'remakes' for the reconstructions (to be added).\n",
        "    \"\"\"\n",
        "    image = features['images']\n",
        "    image_dim = features['height']\n",
        "    image_depth = features['depth']\n",
        "    image_4d = tf.reshape(image, [-1, image_depth, image_dim, image_dim])\n",
        "    conv = self._add_convs(image_4d, [image_depth, 512, 256])\n",
        "    hidden1 = tf.contrib.layers.flatten(conv)\n",
        "\n",
        "    with tf.variable_scope('fc1') as scope:\n",
        "      dim = hidden1.get_shape()[1].value\n",
        "      weights = variables.weight_variable(shape=[dim, 1024], stddev=0.1,\n",
        "                                          verbose=self._hparams.verbose)\n",
        "      biases = variables.bias_variable(shape=[1024],\n",
        "                                       verbose=self._hparams.verbose)\n",
        "      pre_activation = tf.matmul(hidden1, weights) + biases\n",
        "      hidden2 = tf.nn.relu(pre_activation, name=scope.name)\n",
        "\n",
        "    with tf.variable_scope('softmax_layer') as scope:\n",
        "      weights = variables.weight_variable(\n",
        "          shape=[1024, features['num_classes']], stddev=0.1,\n",
        "          verbose=self._hparams.verbose\n",
        "      )\n",
        "      biases = variables.bias_variable(shape=[features['num_classes']],\n",
        "                                       verbose=self._hparams.verbose)\n",
        "      logits = tf.matmul(hidden2, weights) + biases\n",
        "\n",
        "    return model.Inferred(logits, None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d79359a1ce80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \"\"\"A baseline multi GPU Model without capsule layers.\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWq4CyAn1lv8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title model.py\n",
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Basic Model class which provides the optimization wrap around inference.\n",
        "\n",
        "A general model class wrapps the loss and optimizer operations around the\n",
        "inference graph. Therefore, it should define the learning rate, global step\n",
        "and optimizer. The current version supports a multiple gpu scenario by\n",
        "enforcing single gpu to select one gpu for calculations and reuse variables.\n",
        "\n",
        "Different models will only have different inference graphs and they share the\n",
        "training and evaluation ops. Therefore, we define the inference function\n",
        "as an abstract method that each model should define specifically for itself.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import collections\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "TowerResult = collections.namedtuple('TowerResult', ('inferred', 'almost',\n",
        "                                                     'correct', 'grads'))\n",
        "JoinedResult = collections.namedtuple('JoinedResult', ('summary', 'train_op',\n",
        "                                                       'correct', 'almost'))\n",
        "Inferred = collections.namedtuple('Inferred',\n",
        "                                  ('logits', 'remakes'))\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "  \"\"\"Base class for building a model and running inference on it.\"\"\"\n",
        "\n",
        "  __metaclass__ = abc.ABCMeta\n",
        "\n",
        "  def __init__(self, hparams):\n",
        "    \"\"\"Initializes the model parameters.\n",
        "\n",
        "    Args:\n",
        "      hparams: The hyperparameters for the model as tf.contrib.training.HParams.\n",
        "    \"\"\"\n",
        "    self._hparams = hparams\n",
        "    with tf.device('/cpu:0'):\n",
        "      self._global_step = tf.get_variable(\n",
        "          'global_step', [],\n",
        "          initializer=tf.constant_initializer(0),\n",
        "          trainable=False)\n",
        "\n",
        "      learning_rate = tf.train.exponential_decay(\n",
        "          learning_rate=hparams.learning_rate,\n",
        "          global_step=self._global_step,\n",
        "          decay_steps=hparams.decay_steps,\n",
        "          decay_rate=hparams.decay_rate)\n",
        "      learning_rate = tf.maximum(learning_rate, 1e-6)\n",
        "\n",
        "      self._optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def inference(self, features):\n",
        "    \"\"\"Adds the inference graph ops.\n",
        "\n",
        "    Builds the architecture of the neural net to derive logits from features.\n",
        "    The inference graph defined here should involve trainable variables\n",
        "    otherwise the optimizer will raise a ValueError.\n",
        "\n",
        "    Args:\n",
        "      features: Dictionary of batched feature tensors like images and labels.\n",
        "    Returns:\n",
        "      An Inferred named tuple for expected outputs of the model like 'logits'\n",
        "      and 'remakes' for the reconstructions.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError('Not implemented')\n",
        "\n",
        "  def _single_tower(self, tower_ind, feature):\n",
        "    \"\"\"Calculates the model gradient for one tower.\n",
        "\n",
        "    Adds the inference and loss operations to the graph. Calculates the\n",
        "    gradients based on the loss. Appends all the output values of this tower to\n",
        "    their respective lists.\n",
        "\n",
        "    Args:\n",
        "      tower_ind: The index number for this tower. Each tower is named as\n",
        "                  tower_{tower_ind} and resides on gpu:{tower_ind}.\n",
        "      feature: Dictionary of batched features like images and labels.\n",
        "    Returns:\n",
        "      A namedtuple TowerResult containing the inferred values like logits and\n",
        "      reconstructions, gradients and evaluation metrics.\n",
        "    \"\"\"\n",
        "    with tf.device('/gpu:%d' % tower_ind):\n",
        "      with tf.name_scope('tower_%d' % (tower_ind)) as scope:\n",
        "        inferred = self.inference(feature)\n",
        "        losses, correct, almost = layers.evaluate(\n",
        "            logits=inferred.logits,\n",
        "            labels=feature['labels'],\n",
        "            num_targets=feature['num_targets'],\n",
        "            scope=scope,\n",
        "            loss_type=self._hparams.loss_type,)\n",
        "        tf.get_variable_scope().reuse_variables()\n",
        "        grads = self._optimizer.compute_gradients(losses)\n",
        "\n",
        "    return TowerResult(inferred, almost, correct, grads)\n",
        "\n",
        "  def _average_gradients(self, tower_grads):\n",
        "    \"\"\"Calculate the average gradient for each variable across all towers.\n",
        "\n",
        "    Args:\n",
        "      tower_grads: List of gradient lists for each tower. Each gradient list\n",
        "        is a list of (gradient, variable) tuples for all variables.\n",
        "    Returns:\n",
        "      List of pairs of (gradient, variable) where the gradient has been\n",
        "      averaged across all towers.\n",
        "    \"\"\"\n",
        "    average_grads = []\n",
        "    for grads_and_vars in zip(*tower_grads):\n",
        "      grads = tf.stack([g for g, _ in grads_and_vars])\n",
        "      grad = tf.reduce_mean(grads, 0)\n",
        "\n",
        "      v = grads_and_vars[0][1]\n",
        "      grad_and_var = (grad, v)\n",
        "      average_grads.append(grad_and_var)\n",
        "    return average_grads\n",
        "\n",
        "  def _summarize_towers(self, almosts, corrects, tower_grads):\n",
        "    \"\"\"Aggregates the results and gradients over all towers.\n",
        "\n",
        "    Args:\n",
        "      almosts: The number of almost correct samples for each tower.\n",
        "      corrects: The number of correct samples for each tower.\n",
        "      tower_grads: The gradient list for each tower.\n",
        "\n",
        "    Returns:\n",
        "      A JoinedResult of evaluation results, the train op and the summary op.\n",
        "    \"\"\"\n",
        "\n",
        "    grads = self._average_gradients(tower_grads)\n",
        "    train_op = self._optimizer.apply_gradients(\n",
        "        grads, global_step=self._global_step)\n",
        "    summaries = tf.get_collection(tf.GraphKeys.SUMMARIES)\n",
        "    summary = tf.summary.merge(summaries)\n",
        "    stacked_corrects = tf.stack(corrects)\n",
        "    stacked_almosts = tf.stack(almosts)\n",
        "    summed_corrects = tf.reduce_sum(stacked_corrects, 0)\n",
        "    summed_almosts = tf.reduce_sum(stacked_almosts, 0)\n",
        "    return JoinedResult(summary, train_op, summed_corrects, summed_almosts)\n",
        "\n",
        "  def multi_gpu(self, features, num_gpus):\n",
        "    \"\"\"Build the Graph and add the train ops on multiple GPUs.\n",
        "\n",
        "    Divides the inference and gradient computation on multiple gpus.\n",
        "    Then aggregates the gradients and return the resultant ops.\n",
        "\n",
        "    Args:\n",
        "      features: A list of dictionary of different features of input data.\n",
        "                len(features) should be at least num_gpus.\n",
        "      num_gpus: Number of gpus to be distributed on.\n",
        "    Returns:\n",
        "      A tuple of JoinedResult output Ops to be called in Session.run for\n",
        "      training, evaluation or visualization, such as train_op and merged\n",
        "      summary and a list of inferred outputs of each tower.\n",
        "    \"\"\"\n",
        "    almosts = []\n",
        "    corrects = []\n",
        "    tower_grads = []\n",
        "    inferred = []\n",
        "    with tf.variable_scope(tf.get_variable_scope()):\n",
        "      for i in xrange(num_gpus):\n",
        "        tower_output = self._single_tower(i, features[i])\n",
        "        inferred.append(tower_output.inferred)\n",
        "        almosts.append(tower_output.almost)\n",
        "        corrects.append(tower_output.correct)\n",
        "        tower_grads.append(tower_output.grads)\n",
        "\n",
        "    summarized_results = self._summarize_towers(almosts, corrects, tower_grads)\n",
        "    return summarized_results, inferred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdGgHFk81sYc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title layers.py\n",
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Library for capsule layers.\n",
        "\n",
        "This has the layer implementation for coincidence detection, routing and\n",
        "capsule layers.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def _squash(input_tensor):\n",
        "  \"\"\"Applies norm nonlinearity (squash) to a capsule layer.\n",
        "\n",
        "  Args:\n",
        "    input_tensor: Input tensor. Shape is [batch, num_channels, num_atoms] for a\n",
        "      fully connected capsule layer or\n",
        "      [batch, num_channels, num_atoms, height, width] for a convolutional\n",
        "      capsule layer.\n",
        "\n",
        "  Returns:\n",
        "    A tensor with same shape as input (rank 3) for output of this layer.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('norm_non_linearity'):\n",
        "    norm = tf.norm(input_tensor, axis=2, keep_dims=True)\n",
        "    norm_squared = norm * norm\n",
        "    return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n",
        "\n",
        "\n",
        "def _leaky_routing(logits, output_dim):\n",
        "  \"\"\"Adds extra dimmension to routing logits.\n",
        "\n",
        "  This enables active capsules to be routed to the extra dim if they are not a\n",
        "  good fit for any of the capsules in layer above.\n",
        "\n",
        "  Args:\n",
        "    logits: The original logits. shape is\n",
        "      [input_capsule_num, output_capsule_num] if fully connected. Otherwise, it\n",
        "      has two more dimmensions.\n",
        "    output_dim: The number of units in the second dimmension of logits.\n",
        "\n",
        "  Returns:\n",
        "    Routing probabilities for each pair of capsules. Same shape as logits.\n",
        "  \"\"\"\n",
        "\n",
        "  # leak is a zero matrix with same shape as logits except dim(2) = 1 because\n",
        "  # of the reduce_sum.\n",
        "  leak = tf.zeros_like(logits, optimize=True)\n",
        "  leak = tf.reduce_sum(leak, axis=2, keep_dims=True)\n",
        "  leaky_logits = tf.concat([leak, logits], axis=2)\n",
        "  leaky_routing = tf.nn.softmax(leaky_logits, dim=2)\n",
        "  return tf.split(leaky_routing, [1, output_dim], 2)[1]\n",
        "\n",
        "\n",
        "def _update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,\n",
        "                    num_routing, leaky):\n",
        "  \"\"\"Sums over scaled votes and applies squash to compute the activations.\n",
        "\n",
        "  Iteratively updates routing logits (scales) based on the similarity between\n",
        "  the activation of this layer and the votes of the layer below.\n",
        "\n",
        "  Args:\n",
        "    votes: tensor, The transformed outputs of the layer below.\n",
        "    biases: tensor, Bias variable.\n",
        "    logit_shape: tensor, shape of the logit to be initialized.\n",
        "    num_dims: scalar, number of dimmensions in votes. For fully connected\n",
        "      capsule it is 4, for convolutional 6.\n",
        "    input_dim: scalar, number of capsules in the input layer.\n",
        "    output_dim: scalar, number of capsules in the output layer.\n",
        "    num_routing: scalar, Number of routing iterations.\n",
        "    leaky: boolean, if set use leaky routing.\n",
        "\n",
        "  Returns:\n",
        "    The activation tensor of the output layer after num_routing iterations.\n",
        "  \"\"\"\n",
        "  votes_t_shape = [3, 0, 1, 2]\n",
        "  for i in range(num_dims - 4):\n",
        "    votes_t_shape += [i + 4]\n",
        "  r_t_shape = [1, 2, 3, 0]\n",
        "  for i in range(num_dims - 4):\n",
        "    r_t_shape += [i + 4]\n",
        "  votes_trans = tf.transpose(votes, votes_t_shape)\n",
        "\n",
        "  def _body(i, logits, activations):\n",
        "    \"\"\"Routing while loop.\"\"\"\n",
        "    # route: [batch, input_dim, output_dim, ...]\n",
        "    if leaky:\n",
        "      route = _leaky_routing(logits, output_dim)\n",
        "    else:\n",
        "      route = tf.nn.softmax(logits, dim=2)\n",
        "    preactivate_unrolled = route * votes_trans\n",
        "    preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n",
        "    preactivate = tf.reduce_sum(preact_trans, axis=1) + biases\n",
        "    activation = _squash(preactivate)\n",
        "    activations = activations.write(i, activation)\n",
        "    # distances: [batch, input_dim, output_dim]\n",
        "    act_3d = tf.expand_dims(activation, 1)\n",
        "    tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n",
        "    tile_shape[1] = input_dim\n",
        "    act_replicated = tf.tile(act_3d, tile_shape)\n",
        "    distances = tf.reduce_sum(votes * act_replicated, axis=3)\n",
        "    logits += distances\n",
        "    return (i + 1, logits, activations)\n",
        "\n",
        "  activations = tf.TensorArray(\n",
        "      dtype=tf.float32, size=num_routing, clear_after_read=False)\n",
        "  logits = tf.fill(logit_shape, 0.0)\n",
        "  i = tf.constant(0, dtype=tf.int32)\n",
        "  _, logits, activations = tf.while_loop(\n",
        "      lambda i, logits, activations: i < num_routing,\n",
        "      _body,\n",
        "      loop_vars=[i, logits, activations],\n",
        "      swap_memory=True)\n",
        "\n",
        "  return activations.read(num_routing - 1)\n",
        "\n",
        "\n",
        "def capsule(input_tensor,\n",
        "            input_dim,\n",
        "            output_dim,\n",
        "            layer_name,\n",
        "            input_atoms=8,\n",
        "            output_atoms=8,\n",
        "            **routing_args):\n",
        "  \"\"\"Builds a fully connected capsule layer.\n",
        "\n",
        "  Given an input tensor of shape `[batch, input_dim, input_atoms]`, this op\n",
        "  performs the following:\n",
        "\n",
        "    1. For each input capsule, multiples it with the weight variable to get\n",
        "      votes of shape `[batch, input_dim, output_dim, output_atoms]`.\n",
        "    2. Scales the votes for each output capsule by iterative routing.\n",
        "    3. Squashes the output of each capsule to have norm less than one.\n",
        "\n",
        "  Each capsule of this layer has one weight tensor for each capsules of layer\n",
        "  below. Therefore, this layer has the following number of trainable variables:\n",
        "    w: [input_dim * num_in_atoms, output_dim * num_out_atoms]\n",
        "    b: [output_dim * num_out_atoms]\n",
        "\n",
        "  Args:\n",
        "    input_tensor: tensor, activation output of the layer below.\n",
        "    input_dim: scalar, number of capsules in the layer below.\n",
        "    output_dim: scalar, number of capsules in this layer.\n",
        "    layer_name: string, Name of this layer.\n",
        "    input_atoms: scalar, number of units in each capsule of input layer.\n",
        "    output_atoms: scalar, number of units in each capsule of output layer.\n",
        "    **routing_args: dictionary {leaky, num_routing}, args for routing function.\n",
        "\n",
        "  Returns:\n",
        "    Tensor of activations for this layer of shape\n",
        "      `[batch, output_dim, output_atoms]`.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(layer_name):\n",
        "    # weights variable will hold the state of the weights for the layer\n",
        "    weights = variables.weight_variable(\n",
        "        [input_dim, input_atoms, output_dim * output_atoms])\n",
        "    biases = variables.bias_variable([output_dim, output_atoms])\n",
        "    with tf.name_scope('Wx_plus_b'):\n",
        "      # Depthwise matmul: [b, d, c] ** [d, c, o_c] = [b, d, o_c]\n",
        "      # To do this: tile input, do element-wise multiplication and reduce\n",
        "      # sum over input_atoms dimmension.\n",
        "      input_tiled = tf.tile(\n",
        "          tf.expand_dims(input_tensor, -1),\n",
        "          [1, 1, 1, output_dim * output_atoms])\n",
        "      votes = tf.reduce_sum(input_tiled * weights, axis=2)\n",
        "      votes_reshaped = tf.reshape(votes,\n",
        "                                  [-1, input_dim, output_dim, output_atoms])\n",
        "    with tf.name_scope('routing'):\n",
        "      input_shape = tf.shape(input_tensor)\n",
        "      logit_shape = tf.stack([input_shape[0], input_dim, output_dim])\n",
        "      activations = _update_routing(\n",
        "          votes=votes_reshaped,\n",
        "          biases=biases,\n",
        "          logit_shape=logit_shape,\n",
        "          num_dims=4,\n",
        "          input_dim=input_dim,\n",
        "          output_dim=output_dim,\n",
        "          **routing_args)\n",
        "    return activations\n",
        "\n",
        "\n",
        "def _depthwise_conv3d(input_tensor,\n",
        "                      kernel,\n",
        "                      input_dim,\n",
        "                      output_dim,\n",
        "                      input_atoms=8,\n",
        "                      output_atoms=8,\n",
        "                      stride=2,\n",
        "                      padding='SAME'):\n",
        "  \"\"\"Performs 2D convolution given a 5D input tensor.\n",
        "\n",
        "  This layer given an input tensor of shape\n",
        "  `[batch, input_dim, input_atoms, input_height, input_width]` squeezes the\n",
        "  first two dimmensions to get a 4D tensor as the input of tf.nn.conv2d. Then\n",
        "  splits the first dimmension and the last dimmension and returns the 6D\n",
        "  convolution output.\n",
        "\n",
        "  Args:\n",
        "    input_tensor: tensor, of rank 5. Last two dimmensions representing height\n",
        "      and width position grid.\n",
        "    kernel: Tensor, convolutional kernel variables.\n",
        "    input_dim: scalar, number of capsules in the layer below.\n",
        "    output_dim: scalar, number of capsules in this layer.\n",
        "    input_atoms: scalar, number of units in each capsule of input layer.\n",
        "    output_atoms: scalar, number of units in each capsule of output layer.\n",
        "    stride: scalar, stride of the convolutional kernel.\n",
        "    padding: 'SAME' or 'VALID', padding mechanism for convolutional kernels.\n",
        "\n",
        "  Returns:\n",
        "    6D Tensor output of a 2D convolution with shape\n",
        "      `[batch, input_dim, output_dim, output_atoms, out_height, out_width]`,\n",
        "      the convolution output shape and the input shape.\n",
        "      If padding is 'SAME', out_height = in_height and out_width = in_width.\n",
        "      Otherwise, height and width is adjusted with same rules as 'VALID' in\n",
        "      tf.nn.conv2d.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('conv'):\n",
        "    input_shape = tf.shape(input_tensor)\n",
        "    _, _, _, in_height, in_width = input_tensor.get_shape()\n",
        "    # Reshape input_tensor to 4D by merging first two dimmensions.\n",
        "    # tf.nn.conv2d only accepts 4D tensors.\n",
        "\n",
        "    input_tensor_reshaped = tf.reshape(input_tensor, [\n",
        "        input_shape[0] * input_dim, input_atoms, input_shape[3], input_shape[4]\n",
        "    ])\n",
        "    input_tensor_reshaped.set_shape((None, input_atoms, in_height.value,\n",
        "                                     in_width.value))\n",
        "    conv = tf.nn.conv2d(\n",
        "        input_tensor_reshaped,\n",
        "        kernel,\n",
        "        [1, 1, stride, stride],\n",
        "        padding=padding,\n",
        "        data_format='NCHW')\n",
        "    conv_shape = tf.shape(conv)\n",
        "    _, _, conv_height, conv_width = conv.get_shape()\n",
        "    # Reshape back to 6D by splitting first dimmension to batch and input_dim\n",
        "    # and splitting second dimmension to output_dim and output_atoms.\n",
        "\n",
        "    conv_reshaped = tf.reshape(conv, [\n",
        "        input_shape[0], input_dim, output_dim, output_atoms, conv_shape[2],\n",
        "        conv_shape[3]\n",
        "    ])\n",
        "    conv_reshaped.set_shape((None, input_dim, output_dim, output_atoms,\n",
        "                             conv_height.value, conv_width.value))\n",
        "    return conv_reshaped, conv_shape, input_shape\n",
        "\n",
        "\n",
        "def conv_slim_capsule(input_tensor,\n",
        "                      input_dim,\n",
        "                      output_dim,\n",
        "                      layer_name,\n",
        "                      input_atoms=8,\n",
        "                      output_atoms=8,\n",
        "                      stride=2,\n",
        "                      kernel_size=5,\n",
        "                      padding='SAME',\n",
        "                      **routing_args):\n",
        "  \"\"\"Builds a slim convolutional capsule layer.\n",
        "\n",
        "  This layer performs 2D convolution given 5D input tensor of shape\n",
        "  `[batch, input_dim, input_atoms, input_height, input_width]`. Then refines\n",
        "  the votes with routing and applies Squash non linearity for each capsule.\n",
        "\n",
        "  Each capsule in this layer is a convolutional unit and shares its kernel over\n",
        "  the position grid and different capsules of layer below. Therefore, number\n",
        "  of trainable variables in this layer is:\n",
        "\n",
        "    kernel: [kernel_size, kernel_size, input_atoms, output_dim * output_atoms]\n",
        "    bias: [output_dim, output_atoms]\n",
        "\n",
        "  Output of a conv2d layer is a single capsule with channel number of atoms.\n",
        "  Therefore conv_slim_capsule is suitable to be added on top of a conv2d layer\n",
        "  with num_routing=1, input_dim=1 and input_atoms=conv_channels.\n",
        "\n",
        "  Args:\n",
        "    input_tensor: tensor, of rank 5. Last two dimmensions representing height\n",
        "      and width position grid.\n",
        "    input_dim: scalar, number of capsules in the layer below.\n",
        "    output_dim: scalar, number of capsules in this layer.\n",
        "    layer_name: string, Name of this layer.\n",
        "    input_atoms: scalar, number of units in each capsule of input layer.\n",
        "    output_atoms: scalar, number of units in each capsule of output layer.\n",
        "    stride: scalar, stride of the convolutional kernel.\n",
        "    kernel_size: scalar, convolutional kernels are [kernel_size, kernel_size].\n",
        "    padding: 'SAME' or 'VALID', padding mechanism for convolutional kernels.\n",
        "    **routing_args: dictionary {leaky, num_routing}, args to be passed to the\n",
        "      update_routing function.\n",
        "\n",
        "  Returns:\n",
        "    Tensor of activations for this layer of shape\n",
        "      `[batch, output_dim, output_atoms, out_height, out_width]`. If padding is\n",
        "      'SAME', out_height = in_height and out_width = in_width. Otherwise, height\n",
        "      and width is adjusted with same rules as 'VALID' in tf.nn.conv2d.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(layer_name):\n",
        "    kernel = variables.weight_variable(shape=[\n",
        "        kernel_size, kernel_size, input_atoms, output_dim * output_atoms\n",
        "    ])\n",
        "    biases = variables.bias_variable([output_dim, output_atoms, 1, 1])\n",
        "    votes, votes_shape, input_shape = _depthwise_conv3d(\n",
        "        input_tensor, kernel, input_dim, output_dim, input_atoms, output_atoms,\n",
        "        stride, padding)\n",
        "\n",
        "    with tf.name_scope('routing'):\n",
        "      logit_shape = tf.stack([\n",
        "          input_shape[0], input_dim, output_dim, votes_shape[2], votes_shape[3]\n",
        "      ])\n",
        "      biases_replicated = tf.tile(biases,\n",
        "                                  [1, 1, votes_shape[2], votes_shape[3]])\n",
        "      activations = _update_routing(\n",
        "          votes=votes,\n",
        "          biases=biases_replicated,\n",
        "          logit_shape=logit_shape,\n",
        "          num_dims=6,\n",
        "          input_dim=input_dim,\n",
        "          output_dim=output_dim,\n",
        "          **routing_args)\n",
        "    return activations\n",
        "\n",
        "\n",
        "def _margin_loss(labels, raw_logits, margin=0.4, downweight=0.5):\n",
        "  \"\"\"Penalizes deviations from margin for each logit.\n",
        "\n",
        "  Each wrong logit costs its distance to margin. For negative logits margin is\n",
        "  0.1 and for positives it is 0.9. First subtract 0.5 from all logits. Now\n",
        "  margin is 0.4 from each side.\n",
        "\n",
        "  Args:\n",
        "    labels: tensor, one hot encoding of ground truth.\n",
        "    raw_logits: tensor, model predictions in range [0, 1]\n",
        "    margin: scalar, the margin after subtracting 0.5 from raw_logits.\n",
        "    downweight: scalar, the factor for negative cost.\n",
        "\n",
        "  Returns:\n",
        "    A tensor with cost for each data point of shape [batch_size].\n",
        "  \"\"\"\n",
        "  logits = raw_logits - 0.5\n",
        "  positive_cost = labels * tf.cast(tf.less(logits, margin),\n",
        "                                   tf.float32) * tf.pow(logits - margin, 2)\n",
        "  negative_cost = (1 - labels) * tf.cast(\n",
        "      tf.greater(logits, -margin), tf.float32) * tf.pow(logits + margin, 2)\n",
        "  return 0.5 * positive_cost + downweight * 0.5 * negative_cost\n",
        "\n",
        "\n",
        "def evaluate(logits, labels, num_targets, scope, loss_type):\n",
        "  \"\"\"Calculates total loss and performance metrics like accuracy.\n",
        "\n",
        "  Args:\n",
        "    logits: tensor, output of the model.\n",
        "    labels: tensor, ground truth of the data.\n",
        "    num_targets: scalar, number of present objects in the image,\n",
        "      i.e. the number of 1s in labels.\n",
        "    scope: The scope to collect losses of.\n",
        "    loss_type: 'sigmoid' (num_targets > 1), 'softmax' or 'margin' for margin\n",
        "      loss.\n",
        "\n",
        "  Returns:\n",
        "    The total loss of the model, number of correct predictions and number of\n",
        "    cases where at least one of the classes is correctly predicted.\n",
        "  Raises:\n",
        "    NotImplementedError: if the loss_type is not softmax or margin loss.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('loss'):\n",
        "    if loss_type == 'sigmoid':\n",
        "      classification_loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "          labels=labels / 2.0, logits=logits)\n",
        "    elif loss_type == 'softmax':\n",
        "      classification_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
        "          labels=labels, logits=logits)\n",
        "    elif loss_type == 'margin':\n",
        "      classification_loss = _margin_loss(labels=labels, raw_logits=logits)\n",
        "    else:\n",
        "      raise NotImplementedError('Not implemented')\n",
        "\n",
        "    with tf.name_scope('total'):\n",
        "      batch_classification_loss = tf.reduce_mean(classification_loss)\n",
        "      tf.add_to_collection('losses', batch_classification_loss)\n",
        "  tf.summary.scalar('batch_classification_cost', batch_classification_loss)\n",
        "\n",
        "  all_losses = tf.get_collection('losses', scope)\n",
        "  total_loss = tf.add_n(all_losses, name='total_loss')\n",
        "  tf.summary.scalar('total_loss', total_loss)\n",
        "\n",
        "  with tf.name_scope('accuracy'):\n",
        "    with tf.name_scope('correct_prediction'):\n",
        "      _, targets = tf.nn.top_k(labels, k=num_targets)\n",
        "      _, predictions = tf.nn.top_k(logits, k=num_targets)\n",
        "      missed_targets = tf.contrib.metrics.set_difference(targets, predictions)\n",
        "      num_missed_targets = tf.contrib.metrics.set_size(missed_targets)\n",
        "      correct = tf.equal(num_missed_targets, 0)\n",
        "      almost_correct = tf.less(num_missed_targets, num_targets)\n",
        "      correct_sum = tf.reduce_sum(tf.cast(correct, tf.float32))\n",
        "      almost_correct_sum = tf.reduce_sum(tf.cast(almost_correct, tf.float32))\n",
        "    with tf.name_scope('accuracy'):\n",
        "      accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "  tf.summary.scalar('accuracy', accuracy)\n",
        "  tf.summary.scalar('correct_prediction_batch', correct_sum)\n",
        "  tf.summary.scalar('almost_correct_batch', almost_correct_sum)\n",
        "  return total_loss, correct_sum, almost_correct_sum\n",
        "\n",
        "\n",
        "def reconstruction(capsule_mask, num_atoms, capsule_embedding, layer_sizes,\n",
        "                   num_pixels, reuse, image, balance_factor):\n",
        "  \"\"\"Adds the reconstruction loss and calculates the reconstructed image.\n",
        "\n",
        "  Given the last capsule output layer as input of shape [batch, 10, num_atoms]\n",
        "  add 3 fully connected layers on top of it.\n",
        "  Feeds the masked output of the model to the reconstruction sub-network.\n",
        "  Adds the difference with reconstruction image as reconstruction loss to the\n",
        "  loss collection.\n",
        "\n",
        "  Args:\n",
        "    capsule_mask: tensor, for each data in the batch it has the one hot\n",
        "      encoding of the target id.\n",
        "    num_atoms: scalar, number of atoms in the given capsule_embedding.\n",
        "    capsule_embedding: tensor, output of the last capsule layer.\n",
        "    layer_sizes: (scalar, scalar), size of the first and second layer.\n",
        "    num_pixels: scalar, number of pixels in the target image.\n",
        "    reuse: if set reuse variables.\n",
        "    image: The reconstruction target image.\n",
        "    balance_factor: scalar, downweight the loss to be in valid range.\n",
        "\n",
        "  Returns:\n",
        "    The reconstruction images of shape [batch_size, num_pixels].\n",
        "  \"\"\"\n",
        "  first_layer_size, second_layer_size = layer_sizes\n",
        "  capsule_mask_3d = tf.expand_dims(capsule_mask, -1)\n",
        "  atom_mask = tf.tile(capsule_mask_3d, [1, 1, num_atoms])\n",
        "  filtered_embedding = capsule_embedding * atom_mask\n",
        "  filtered_embedding_2d = tf.contrib.layers.flatten(filtered_embedding)\n",
        "  reconstruction_2d = tf.contrib.layers.stack(\n",
        "      inputs=filtered_embedding_2d,\n",
        "      layer=tf.contrib.layers.fully_connected,\n",
        "      stack_args=[(first_layer_size, tf.nn.relu),\n",
        "                  (second_layer_size, tf.nn.relu),\n",
        "                  (num_pixels, tf.sigmoid)],\n",
        "      reuse=reuse,\n",
        "      scope='recons',\n",
        "      weights_initializer=tf.truncated_normal_initializer(\n",
        "          stddev=0.1, dtype=tf.float32),\n",
        "      biases_initializer=tf.constant_initializer(0.1))\n",
        "\n",
        "  with tf.name_scope('loss'):\n",
        "    image_2d = tf.contrib.layers.flatten(image)\n",
        "    distance = tf.pow(reconstruction_2d - image_2d, 2)\n",
        "    loss = tf.reduce_sum(distance, axis=-1)\n",
        "    batch_loss = tf.reduce_mean(loss)\n",
        "    balanced_loss = balance_factor * batch_loss\n",
        "    tf.add_to_collection('losses', balanced_loss)\n",
        "    tf.summary.scalar('reconstruction_error', balanced_loss)\n",
        "\n",
        "  return reconstruction_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeL9IRsd1vrc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title variables.py\n",
        "# Copyright 2017 The TensorFlow Authors All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\"\"\"Utility functions for declaring variables and adding summaries.\n",
        "\n",
        "It adds all different scalars and histograms for each variable and provides\n",
        "utility functions for weight and bias variables.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def weight_variable(shape, stddev=0.1, verbose=False):\n",
        "  \"\"\"Creates a CPU variable with normal initialization. Adds summaries.\n",
        "\n",
        "  Args:\n",
        "    shape: list, the shape of the variable.\n",
        "    stddev: scalar, standard deviation for the initilizer.\n",
        "    verbose: if set add histograms.\n",
        "\n",
        "  Returns:\n",
        "    Weight variable tensor of shape=shape.\n",
        "  \"\"\"\n",
        "  with tf.device('/cpu:0'):\n",
        "    with tf.name_scope('weights'):\n",
        "      weights = tf.get_variable(\n",
        "          'weights',\n",
        "          shape,\n",
        "          initializer=tf.truncated_normal_initializer(\n",
        "              stddev=stddev, dtype=tf.float32),\n",
        "          dtype=tf.float32)\n",
        "  variable_summaries(weights, verbose)\n",
        "  return weights\n",
        "\n",
        "\n",
        "def bias_variable(shape, verbose=False):\n",
        "  \"\"\"Creates a CPU variable with constant initialization. Adds summaries.\n",
        "\n",
        "  Args:\n",
        "    shape: list, the shape of the variable.\n",
        "    verbose: if set add histograms.\n",
        "\n",
        "  Returns:\n",
        "    Bias variable tensor with shape=shape.\n",
        "  \"\"\"\n",
        "  with tf.device('/cpu:0'):\n",
        "    with tf.name_scope('biases'):\n",
        "      biases = tf.get_variable(\n",
        "          'biases',\n",
        "          shape,\n",
        "          initializer=tf.constant_initializer(0.1),\n",
        "          dtype=tf.float32)\n",
        "  variable_summaries(biases, verbose)\n",
        "  return biases\n",
        "\n",
        "\n",
        "def variable_summaries(var, verbose):\n",
        "  \"\"\"Attaches a lot of summaries to a Tensor (for TensorBoard visualization).\n",
        "\n",
        "  Args:\n",
        "    var: tensor, statistic summaries of this tensor is added.\n",
        "    verbose: if set add histograms.\n",
        "  \"\"\"\n",
        "  if verbose:\n",
        "    with tf.name_scope('summaries'):\n",
        "      mean = tf.reduce_mean(var)\n",
        "      tf.summary.scalar('mean', mean)\n",
        "\n",
        "      with tf.name_scope('stddev'):\n",
        "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
        "      tf.summary.scalar('stddev', stddev)\n",
        "      tf.summary.scalar('max', tf.reduce_max(var))\n",
        "      tf.summary.scalar('min', tf.reduce_min(var))\n",
        "      tf.summary.histogram('histogram', var)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "\n",
        "def activation_summary(x, verbose):\n",
        "  \"\"\"Creates summaries for activations.\n",
        "\n",
        "  Creates a summary that provides a histogram and sparsity of activations.\n",
        "\n",
        "  Args:\n",
        "    x: Tensor\n",
        "    verbose: if set add histograms.\n",
        "  \"\"\"\n",
        "  if verbose:\n",
        "    tf.summary.histogram('activations', x)\n",
        "    tf.summary.scalar('sparsity', tf.nn.zero_fraction(x))\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}